<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Software Engineering</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="index.html">Software Engineering</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><li class="part-title">Chapters</li><li class="chapter-item expanded "><a href="chapters/DevOps/index.html"><strong aria-hidden="true">1.</strong> DevOps</a></li><li class="chapter-item expanded "><a href="chapters/Flutter/index.html"><strong aria-hidden="true">2.</strong> Flutter</a></li><li class="chapter-item expanded "><a href="chapters/Infrastructure_As_Code/index.html"><strong aria-hidden="true">3.</strong> Infrastructure As Code</a></li><li class="chapter-item expanded "><a href="chapters/Machine_Learning/index.html"><strong aria-hidden="true">4.</strong> Machine Learning</a></li><li class="chapter-item expanded "><a href="chapters/Software_Architecture/index.html"><strong aria-hidden="true">5.</strong> Software Architecture</a></li><li class="chapter-item expanded "><a href="chapters/Software_Testing/index.html"><strong aria-hidden="true">6.</strong> Software Testing</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Software Engineering</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>This online book serves as a useful resource for professionals in the software and technology fields. You'll find concise, yet comprehensive coverage of the latest trends, tools, and techniques shaping our digital world.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="devops"><a class="header" href="#devops">DevOps</a></h1>
<hr />
<h2 id="table-of-contents"><a class="header" href="#table-of-contents">Table of Contents</a></h2>
<ul>
<li><a href="chapters/DevOps/index.html#data-formats">Data Formats</a>
<ul>
<li><a href="chapters/DevOps/index.html#xml">XML</a></li>
<li><a href="chapters/DevOps/index.html#json">JSON</a></li>
<li><a href="chapters/DevOps/index.html#yaml">YAML</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#git">Git</a>
<ul>
<li><a href="chapters/DevOps/index.html#setting-up-git">Setting Up Git</a></li>
<li><a href="chapters/DevOps/index.html#commit">Commit</a></li>
<li><a href="chapters/DevOps/index.html#tag">Tag</a></li>
<li><a href="chapters/DevOps/index.html#branch">Branch</a></li>
<li><a href="chapters/DevOps/index.html#terminology">Terminology</a></li>
<li><a href="chapters/DevOps/index.html#distributed-version-control-system">Distributed Version Control System</a></li>
<li><a href="chapters/DevOps/index.html#setting-up-a-repository">Setting Up A Repository</a></li>
<li><a href="chapters/DevOps/index.html#inspecting-a-repository">Inspecting A Repository</a></li>
<li><a href="chapters/DevOps/index.html#undoing-commits-and-changes">Undoing Commits And Changes</a></li>
<li><a href="chapters/DevOps/index.html#pull-requests">Pull Requests</a></li>
<li><a href="chapters/DevOps/index.html#merge">Merge</a></li>
<li><a href="chapters/DevOps/index.html#branch-workflow">Branch Workflow</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#virtualization">Virtualization</a>
<ul>
<li><a href="chapters/DevOps/index.html#hardware-virtualization">Hardware Virtualization</a></li>
<li><a href="chapters/DevOps/index.html#terminology">Terminology</a></li>
<li><a href="chapters/DevOps/index.html#advantages">Advantages</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#docker">Docker</a>
<ul>
<li><a href="chapters/DevOps/index.html#benefits">Benefits</a></li>
<li><a href="chapters/DevOps/index.html#containers-vs-vms">Containers vs VMs</a></li>
<li><a href="chapters/DevOps/index.html#basic-docker-workflow">Basic Docker Workflow</a></li>
<li><a href="chapters/DevOps/index.html#image">Image</a></li>
<li><a href="chapters/DevOps/index.html#container">Container</a></li>
<li><a href="chapters/DevOps/index.html#image-vs-container">Image vs Container</a></li>
<li><a href="chapters/DevOps/index.html#dockerfile">Dockerfile</a></li>
<li><a href="chapters/DevOps/index.html#mount-volumes">Mount Volumes</a></li>
<li><a href="chapters/DevOps/index.html#publish-port">Publish Port</a></li>
<li><a href="chapters/DevOps/index.html#docker-compose">Docker Compose</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#portainer">Portainer</a>
<ul>
<li><a href="chapters/DevOps/index.html#installation">Installation</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#ansible">Ansible</a>
<ul>
<li><a href="chapters/DevOps/index.html#ssh-or-winrm">SSH Or WinRM</a></li>
<li><a href="chapters/DevOps/index.html#inventory">Inventory</a></li>
<li><a href="chapters/DevOps/index.html#playbook">Playbook</a></li>
<li><a href="chapters/DevOps/index.html#task">Task</a></li>
<li><a href="chapters/DevOps/index.html#role">Role</a></li>
<li><a href="chapters/DevOps/index.html#facts">Facts</a></li>
<li><a href="chapters/DevOps/index.html#modules">Modules</a></li>
<li><a href="chapters/DevOps/index.html#variables">Variables</a></li>
</ul>
</li>
<li><a href="chapters/DevOps/index.html#terraform">Terraform</a>
<ul>
<li><a href="chapters/DevOps/index.html#configuration">Configuration</a></li>
<li><a href="chapters/DevOps/index.html#commands">Commands</a></li>
<li><a href="chapters/DevOps/index.html#local-state">Local State</a></li>
<li><a href="chapters/DevOps/index.html#remote-state">Remote State</a></li>
<li><a href="chapters/DevOps/index.html#plan--apply">Plan / Apply</a></li>
<li><a href="chapters/DevOps/index.html#terraform-variables">Terraform Variables</a></li>
</ul>
</li>
</ul>
<hr />
<h2 id="data-formats"><a class="header" href="#data-formats">Data Formats</a></h2>
<p>We need a standard format to allow a diverse set of software to communicate with each other, and for humans to interface with it. All of the data formats that we’ll discuss in this chapter have broad support over a multitude of languages and operating systems.</p>
<ul>
<li>
<p><strong>XML</strong> - machine to machine</p>
</li>
<li>
<p><strong>JSON</strong> - machine to machine</p>
</li>
<li>
<p><strong>YAML</strong> – human to machine</p>
</li>
</ul>
<h3 id="xml"><a class="header" href="#xml">XML</a></h3>
<p>XML is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable. The design goals of XML emphasize simplicity, generality, and usability across the Internet.</p>
<h4 id="features"><a class="header" href="#features">Features</a></h4>
<ul>
<li>
<p>XML files end in <code>.xml</code>.</p>
</li>
<li>
<p>Root, children nodes, attributes.</p>
</li>
<li>
<p>Namespaces (Used to resolve naming conflicts).</p>
</li>
</ul>
<p><img src="chapters/DevOps/./images/image1.png" alt="XML" /></p>
<h4 id="benefits"><a class="header" href="#benefits">Benefits</a></h4>
<ul>
<li>
<p>Support inter-business transactions.</p>
</li>
<li>
<p>Maintain data integrity.</p>
<ul>
<li>Verify data accuracy.</li>
<li>Automatically customize data presentation for different users.</li>
<li>Store data consistently across multiple platforms.</li>
</ul>
</li>
<li>
<p>Improve search efficiency.</p>
</li>
<li>
<p>Design flexible applications.</p>
</li>
</ul>
<h3 id="json"><a class="header" href="#json">JSON</a></h3>
<p>JSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate.</p>
<h4 id="features-1"><a class="header" href="#features-1">Features</a></h4>
<ul>
<li>
<p>JSON files end in <code>.json</code>.</p>
</li>
<li>
<p>The whole thing is wrapped in curly braces {}. This is very common, and it indicates that JSON objects are contained inside.</p>
</li>
<li>
<p>Think of “objects” as key-value pairs, or dictionaries.</p>
</li>
<li>
<p>JSON objects always use string values when describing the keys.</p>
</li>
<li>
<p>JSON list indicated by the square brackets [].</p>
</li>
<li>
<p>Data Types:</p>
<ul>
<li>Number</li>
<li>String</li>
<li>Boolean</li>
<li>Array</li>
<li>Object</li>
<li>Null</li>
</ul>
</li>
</ul>
<p><img src="chapters/DevOps/./images/image2.png" alt="JSON" /></p>
<h4 id="working-with-json-in-python"><a class="header" href="#working-with-json-in-python">Working with JSON in Python</a></h4>
<ul>
<li>JSON enjoys wide support across a myriad of languages</li>
<li>You will often be able to simply import a JSON data structure into constructs of a given language, simply with a one-line command</li>
</ul>
<pre><code class="language-python">import json

item = {
    "name": "egg",
    "price": 0.99,
}

with open('data.json', 'w') as f:
    json.dump(item, f) # write python object to json file

with open('data.json', 'r') as f:
    data = json.load(f) # load json data into python object

print(data) # {'name': 'egg', 'price': 0.99}
</code></pre>
<h3 id="yaml"><a class="header" href="#yaml">YAML</a></h3>
<p>YAML (YAML Ain't Markup Language) is a human-readable data serialization language. It is commonly used for configuration files, automation workflow, or providing a data set
to work with.</p>
<h4 id="features-2"><a class="header" href="#features-2">Features</a></h4>
<ul>
<li>
<p>YAML files end in <code>.yaml</code> or <code>.yml</code>.</p>
</li>
<li>
<p>YAML is a superset of JSON.</p>
</li>
<li>
<p>YAML is a human-readable data serialization language.</p>
</li>
<li>
<p>YAML is a strict indentation language.</p>
</li>
<li>
<p>YAML is case sensitive.</p>
</li>
</ul>
<p><img src="chapters/DevOps/./images/image3.png" alt="YAML" /></p>
<h4 id="working-with-yaml-in-python"><a class="header" href="#working-with-yaml-in-python">Working with YAML in Python</a></h4>
<pre><code class="language-python">import yaml

item = {
    "name": "egg",
    "price": 0.99,
}

with open('data.yaml', 'w') as f:
    yaml.dump(item, f) # write python object to yaml file

with open('data.yaml', 'r') as f:
    data = yaml.load(f, Loader=yaml.FullLoader) # load yaml data into python object

print(data) # {'name': 'egg', 'price': 0.99}
</code></pre>
<p>Note: The yaml module is not part of the standard library, so you’ll need to install it first. You can do so with pip:</p>
<pre><code class="language-bash">pip install pyyaml
</code></pre>
<hr />
<h2 id="git"><a class="header" href="#git">Git</a></h2>
<p><img src="chapters/DevOps/./images/image10.png" alt="Git" /></p>
<p>Source code management systems are essential for any software development project. They allow you to keep track of your software at the source level. You can track changes, revert to previous stages, and work on different branches at the same time. Code is organized within a repository.</p>
<h3 id="setting-up-git"><a class="header" href="#setting-up-git">Setting Up Git</a></h3>
<pre><code class="language-bash">git config --global user.name &lt;name&gt;    # Set user name

git config --global user.email &lt;email&gt;  # Set user email
</code></pre>
<h3 id="commit"><a class="header" href="#commit">Commit</a></h3>
<ul>
<li>
<p>Specific snapshot within the development tree.</p>
</li>
<li>
<p>Collection of changes applied to a project's files.</p>
</li>
<li>
<p>Metadata about the change.</p>
</li>
<li>
<p>Identified by a unique <code>SHA-1 Hash</code>.</p>
</li>
</ul>
<pre><code class="language-bash">git commit -m "Add new feature"   # Commit changes

git show 5b8e4f                   # Show commit details
</code></pre>
<h3 id="tag"><a class="header" href="#tag">Tag</a></h3>
<ul>
<li>
<p>Represents a single commit.</p>
</li>
<li>
<p>Often human-friendly.</p>
</li>
<li>
<p>Version number.</p>
</li>
</ul>
<pre><code class="language-bash">git tag v1.0.0    # Create a tag

git tag           # List all tags

git show v1.0.0   # Show tag details
</code></pre>
<h3 id="branch"><a class="header" href="#branch">Branch</a></h3>
<ul>
<li>
<p>A history of successive changes to code.</p>
</li>
<li>
<p>A new branch may be created at any time, from any existing commit.</p>
</li>
<li>
<p>May represent versions of code.</p>
</li>
</ul>
<pre><code class="language-bash">git branch                        # List all branches

git branch feature/add-btn        # Create a new branch

git checkout feature/add-btn      # Switch to a branch

git checkout -b feature/add-btn   # Create and switch to a branch
</code></pre>
<p><img src="chapters/DevOps/./images/image4.png" alt="Git Branch" /></p>
<h3 id="terminology"><a class="header" href="#terminology">Terminology</a></h3>
<ul>
<li>
<p><strong>Working Files</strong>: Files that are currently on your file system.</p>
</li>
<li>
<p><strong>Staging Area</strong>: Files that are ready to be committed. Only files that have been staged will be committed.</p>
</li>
<li>
<p><strong>Checkout</strong>: Replace the current directory files with those from a specific branch or commit.</p>
</li>
</ul>
<p><img src="chapters/DevOps/./images/image5.png" alt="Git Model" /></p>
<h3 id="distributed-version-control-system"><a class="header" href="#distributed-version-control-system">Distributed Version Control System</a></h3>
<ul>
<li>
<p><strong>Clone</strong>: Creates a full copy of repository on your local machine.</p>
</li>
<li>
<p><strong>Fetch</strong>: Update your local repository with changes from non-local repositories (i.e. GitHub).</p>
</li>
<li>
<p><strong>Fork</strong>: Create a copy of a repository in a remote location (i.e. GitHub).</p>
</li>
</ul>
<pre><code class="language-bash">git clone https://github.com/username/repo.git   # Clone a repository

git fetch origin                                # Fetch changes from remote repository
</code></pre>
<h3 id="setting-up-a-repository"><a class="header" href="#setting-up-a-repository">Setting Up A Repository</a></h3>
<ul>
<li>Create a new repository from cero on the command line</li>
</ul>
<pre><code class="language-bash">git init                                                    # Initialize a new repository

git remote add origin https://github.com/username/repo.git  # Add a remote repository
</code></pre>
<ul>
<li>Clone an existing repository</li>
</ul>
<pre><code class="language-bash">git clone https://github.com/username/repo.git    # Clone a repository

cd repo                                           # Change directory to the repository
</code></pre>
<h3 id="inspecting-a-repository"><a class="header" href="#inspecting-a-repository">Inspecting A Repository</a></h3>
<ul>
<li>
<p><strong>git diff</strong>: Show changes between commits, commit and working tree, etc.</p>
</li>
<li>
<p><strong>git status</strong>: Display the state of the working directory and the staging area.</p>
</li>
<li>
<p><strong>git blame</strong>: Examine the history of a file and get context as to who made changes and when.</p>
</li>
<li>
<p><strong>git log</strong>: Show commit logs.</p>
</li>
</ul>
<pre><code class="language-bash">git diff ./file.txt    # Show changes between commits, commit and working tree, etc.

git status            # Display the state of the working directory and the staging area

git blame ./file.txt  # Examine the history of a file

git log               # Show commit logs
</code></pre>
<p><img src="chapters/DevOps/./images/image6.png" alt="Git diff" /></p>
<h3 id="undoing-commits-and-changes"><a class="header" href="#undoing-commits-and-changes">Undoing Commits And Changes</a></h3>
<ul>
<li>
<p><strong>git revert</strong>: Create a new commit that undoes the changes from a previous commit.</p>
</li>
<li>
<p><strong>git commit --amend</strong>: Change the last commit.</p>
</li>
<li>
<p><strong>git reset --soft</strong>: Only resets the HEAD to the commit you specified.</p>
</li>
<li>
<p><strong>git reset --mixed</strong>: Resets the HEAD to the commit you specified and resets the staging area.</p>
</li>
<li>
<p><strong>git reset --hard</strong>: Resets the HEAD to the commit you specified and resets the staging area and working directory.</p>
</li>
</ul>
<pre><code class="language-bash">git revert 5b8e4f    # Create a new commit that undoes the changes from a previous commit

git commit --amend   # Change the last commit

git reset --soft 5b8e4f    # Only resets the HEAD to the commit you specified

git reset --mixed 5b8e4f   # Resets the HEAD to the commit you specified and resets the staging area

git reset --hard 5b8e4f    # Resets the HEAD to the commit you specified and resets the staging area and working directory
</code></pre>
<h3 id="pull-requests"><a class="header" href="#pull-requests">Pull Requests</a></h3>
<p>Pull requests are a mechanism for a developer to notify team members that they have completed a feature. Once their feature branch is ready, the developer files a pull request via their SCM (Source Control Management) system. This allows team members to review the changes and discuss any potential modifications.</p>
<p><img src="chapters/DevOps/./images/image7.png" alt="Pull Request" /></p>
<h3 id="merge"><a class="header" href="#merge">Merge</a></h3>
<p>A merge is the act of integrating the changes from one branch or commit into a second branch. The result is a new commit that is a combination of the two. If a merge fails, git will notify you with a merge conflict. Merge conflixts must be fixed manually, and then added and committed.</p>
<p><strong>NOTE</strong>: Merge conflicts occur when two branches have changed the same part of the same file, and then those branches are merged together. Git will not be able to automatically determine what the correct content should be or if both changes should be included, so you must inspect and resolve the conflict manually.</p>
<pre><code class="language-bash">git merge feature/add-btn    # Merge a branch into the current branch
</code></pre>
<h3 id="branch-workflow"><a class="header" href="#branch-workflow">Branch Workflow</a></h3>
<p>Feature branching is a git workflow that allows multiple developers to work on a particular feature in isolation. Each feature is developed in a dedicated branch, and once it is ready, it is merged into the main branch.</p>
<p><img src="chapters/DevOps/./images/image9.png" alt="Branch Workflow" /></p>
<hr />
<h2 id="virtualization"><a class="header" href="#virtualization">Virtualization</a></h2>
<p><img src="chapters/DevOps/./images/image8.png" alt="Virtualization" /></p>
<h3 id="hardware-virtualization"><a class="header" href="#hardware-virtualization">Hardware Virtualization</a></h3>
<ul>
<li>
<p>Abstract underlying physical hardware from operating systems and applications.</p>
</li>
<li>
<p>Allows multiple guest operating systems to run in parallel.</p>
</li>
<li>
<p>Physical resources are shared among all guest OS and virtualization software.</p>
</li>
</ul>
<h3 id="terminology-1"><a class="header" href="#terminology-1">Terminology</a></h3>
<ul>
<li>
<p><strong>Host OS/Host Machine</strong>: Physical hardware/server.</p>
</li>
<li>
<p><strong>Hypervisor</strong>: The virtualization software, acts as the true OS for the server.</p>
</li>
<li>
<p><strong>Guest OS/Virtual Machines</strong>: Instances of the virtualized OS, running in emulated environments. Guest thinks it’s running on real hardware.</p>
</li>
</ul>
<h3 id="advantages"><a class="header" href="#advantages">Advantages</a></h3>
<ul>
<li>
<p><strong>Sandbox</strong>: Isolated from the host OS.</p>
</li>
<li>
<p><strong>Networked</strong>: Access over the network.</p>
</li>
<li>
<p><strong>Portable</strong>: Run on any host OS.</p>
</li>
<li>
<p><strong>Snapshots</strong>: Saved and restored to previous states.</p>
</li>
</ul>
<hr />
<h2 id="docker"><a class="header" href="#docker">Docker</a></h2>
<p><img src="chapters/DevOps/./images/image11.png" alt="Docker" /></p>
<p>Docker is a platform for developers and sysadmins to develop, deploy, and run applications with containers. The use of Linux containers to deploy applications is called containerization.</p>
<h3 id="benefits-1"><a class="header" href="#benefits-1">Benefits</a></h3>
<ul>
<li>
<p><strong>Flexible</strong>: Even the most complex applications can be containerized.</p>
</li>
<li>
<p><strong>Lightweight</strong>: Containers leverage and share the host kernel.</p>
</li>
<li>
<p><strong>Interchangeable</strong>: You can deploy updates and upgrades on-the-fly.</p>
</li>
<li>
<p><strong>Portable</strong>: You can build locally, deploy to the cloud, and run anywhere.</p>
</li>
<li>
<p><strong>Scalable</strong>: You can increase and automatically distribute container replicas.</p>
</li>
<li>
<p><strong>Stackable</strong>: You can stack services vertically and on-the-fly.</p>
</li>
</ul>
<h3 id="containers-vs-vms"><a class="header" href="#containers-vs-vms">Containers vs VMs</a></h3>
<p>Container are isolated, but share OS and, where appropriate, bins/libraries. VMs are isolated, but each has its own OS, bins, and libraries. This results in significantly faster deployment, much less overhead, easier migration and faster restart.</p>
<p><img src="chapters/DevOps/./images/image12.png" alt="Containers vs VMs" /></p>
<h3 id="basic-docker-workflow"><a class="header" href="#basic-docker-workflow">Basic Docker Workflow</a></h3>
<p><img src="chapters/DevOps/./images/image13.png" alt="Workflow" /></p>
<h3 id="image"><a class="header" href="#image">Image</a></h3>
<p>Persisted snapshot that can be run as a container.</p>
<ul>
<li>
<p><strong>images</strong>: List all local images.</p>
</li>
<li>
<p><strong>run</strong>: Create a container from an image and execute a command in it.</p>
</li>
<li>
<p><strong>tag</strong>: Tag an image.</p>
</li>
<li>
<p><strong>pull</strong>: Download an image from a registry.</p>
</li>
<li>
<p><strong>rmi</strong>: Delete a local image.</p>
</li>
</ul>
<pre><code class="language-bash">docker images                     # List all local images

docker run -it ubuntu /bin/bash   # Create a container from an image and execute a command in it

docker tag ubuntu my-ubuntu       # Tag an image

docker pull ubuntu                # Download an image from a registry

docker rmi ubuntu                 # Delete a local image
</code></pre>
<h3 id="container"><a class="header" href="#container">Container</a></h3>
<p>Runnable instance of an image.</p>
<ul>
<li>
<p><strong>ps</strong>: List all running containers.</p>
</li>
<li>
<p><strong>ps -a</strong>: List all containers (running and stopped).</p>
</li>
<li>
<p><strong>top</strong>: Display processes of a container.</p>
</li>
<li>
<p><strong>start</strong>: Start a stopped container.</p>
</li>
<li>
<p><strong>stop</strong>: Stop a running container.</p>
</li>
<li>
<p><strong>pause</strong>: Pause all processes within a container.</p>
</li>
<li>
<p><strong>rm</strong>: Delete a container.</p>
</li>
<li>
<p><strong>commit</strong>: Create an image from a container.</p>
</li>
</ul>
<pre><code class="language-bash">docker ps                      # List all running containers

docker ps -a                   # List all containers (running and stopped)

docker top &lt;container_id&gt;      # Display processes of a container

docker start &lt;container_id&gt;    # Start a stopped container

docker stop &lt;container_id&gt;     # Stop a running container

docker pause &lt;container_id&gt;    # Pause all processes within a container

docker rm &lt;container_id&gt;       # Delete a container
</code></pre>
<h3 id="image-vs-container"><a class="header" href="#image-vs-container">Image vs Container</a></h3>
<p><img src="chapters/DevOps/./images/image14.png" alt="Image vs Container" /></p>
<h3 id="dockerfile"><a class="header" href="#dockerfile">Dockerfile</a></h3>
<p>Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Can be versioned in a version control system like Git or
SVN, along with all dependencies. Docker Hub can automatically build images based on
dockerfiles on Github WorkFlows.</p>
<ul>
<li>Configuration is done in a <code>Dockerfile</code>.</li>
</ul>
<pre><code class="language-Dockerfile">FROM ubuntu
ENV DOCK_MESSAGE Hello My World
ADD dir /files
CMD ["bash", "echo $DOCK_MESSAGE"]
</code></pre>
<p>The above <code>Dockerfile</code> will create an image from the <code>ubuntu</code> image, set an environment variable, add a directory to the image, and run a command.</p>
<ul>
<li>Run the following commands to build and run the image:</li>
</ul>
<pre><code class="language-bash">docker build .              # Build an image from a Dockerfile

docker inspect &lt;image_id&gt;   # Return low-level information on Docker objects
</code></pre>
<h3 id="mount-volumes"><a class="header" href="#mount-volumes">Mount Volumes</a></h3>
<p>Volumes allow data to persist beyond the lifetime of a container.</p>
<pre><code class="language-bash">docker run -it -v /hostLog:/log ubuntu  # Mount a volume to a container
</code></pre>
<p>Run a second container, volume can be shared between containers.</p>
<pre><code class="language-bash">docker run -it --volumes-from &lt;container_id&gt; ubuntu  # Mount a volume from another container
</code></pre>
<h3 id="publish-port"><a class="header" href="#publish-port">Publish Port</a></h3>
<p>Port mapping allows a container to expose a port to the host.</p>
<pre><code class="language-bash">docker run -p 8080:80 nginx  # Publish a container's port to the host
</code></pre>
<p>This will allow you to access the container's port 80 from the host's port 8080.</p>
<ul>
<li>
<p><code>8080</code> Host Port (computer running the container)</p>
</li>
<li>
<p><code>80</code> Container Port (inside the container)</p>
</li>
</ul>
<p>You can link containers together, so that they can communicate with each other.</p>
<pre><code class="language-bash">docker run --link &lt;container_id&gt;:&lt;alias&gt; &lt;image&gt;  # Link a container to another container
</code></pre>
<h3 id="docker-compose"><a class="header" href="#docker-compose">Docker Compose</a></h3>
<p>Docker Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration.</p>
<ul>
<li>Configuration is done in a <code>docker-compose.yml</code> file.</li>
</ul>
<pre><code class="language-yaml">version: "3"

services:
  postgres:
    image: postgres
    environment:
      POSTGRES_PASSWORD: root
    ports:
      - "5432:5432"
    volumes:
      - db:/var/lib/postgresql/data
    networks:
      - postgres

  pgadmin4:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: pgadmin4@pgadmin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    networks:
      - postgres
    volumes:
      - pgadmin:/var/lib/pgadmin

networks:
  postgres:
    driver: bridge

volumes:
  db:
  pgadmin:
</code></pre>
<p>The above <code>docker-compose.yml</code> file will create two services, <code>postgres</code> and <code>pgadmin4</code>. The <code>postgres</code> service will use the <code>postgres</code> image, and the <code>pgadmin4</code> service will use the <code>dpage/pgadmin4</code> image. The volume is used to persist the data of each service. The network is used to connect both services with each other.</p>
<ul>
<li>Run the following commands to start and stop the services:</li>
</ul>
<pre><code class="language-bash">docker-compose up    # Create and start all the services from your configuration

docker-compose down  # Stop and remove containers, networks, images, and volumes
</code></pre>
<hr />
<h2 id="portainer"><a class="header" href="#portainer">Portainer</a></h2>
<p><img src="chapters/DevOps/./images/image15.png" alt="Portainer" /></p>
<p>Portainer is a lightweight management UI which allows you to easily manage your Docker host or Swarm cluster.</p>
<ul>
<li>
<p><strong>Portainer Agent</strong>: A container that runs on each Docker host and Swarm manager. It is responsible for managing the local Docker environment.</p>
</li>
<li>
<p><strong>Portainer Server</strong>: A container that runs on the Docker host and is responsible for managing the Portainer Agent.</p>
</li>
</ul>
<h3 id="installation"><a class="header" href="#installation">Installation</a></h3>
<ol>
<li>Run the following commands to install Portainer:</li>
</ol>
<pre><code class="language-bash">docker volume create portainer_data

docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest
</code></pre>
<ol start="2">
<li>
<p>Open your web browser and navigate to <code>http://localhost:8000</code>.</p>
</li>
<li>
<p>Create an admin user and password.</p>
</li>
<li>
<p>Select <code>Local</code> and click <code>Connect</code>.</p>
</li>
<li>
<p>You will be redirected to the Portainer dashboard.</p>
</li>
</ol>
<hr />
<h2 id="ansible"><a class="header" href="#ansible">Ansible</a></h2>
<p><img src="chapters/DevOps/./images/image16.png" alt="Ansible" /></p>
<p>Ansible is an open-source IT automation tool that simplifies and automates various manual IT processes, including provisioning, configuration management, application deployment, and orchestration.</p>
<p>Ansible uses a declarative language called <code>YAML</code> to define automation tasks, which makes it easy to read and understand.</p>
<p>Ansible is agentless, which means it doesn’t require any software or agents to be installed on the target hosts (managed nodes).</p>
<h3 id="ssh-or-winrm"><a class="header" href="#ssh-or-winrm">SSH Or WinRM</a></h3>
<p>Ansible communicates with the managed nodes using SSH (for Unix-based systems) or WinRM (for Windows systems).</p>
<pre><code class="language-yaml">ansible_ssh_user: root
ansible_ssh_pass: password
</code></pre>
<p><em>The above configuration will allow Ansible to communicate with the managed nodes using <code>SSH</code>.</em></p>
<h3 id="inventory"><a class="header" href="#inventory">Inventory</a></h3>
<p>Ansible uses an inventory file that lists the IP addresses or hostnames of the managed nodes. This inventory can be static (defined in a file) or dynamic (generated programmatically).</p>
<pre><code class="language-yaml">webservers:
  hosts:
    web1:
    web2:
    web3:
</code></pre>
<p><em>The above inventory file contains a list of hosts in the <code>webservers</code> group.</em></p>
<h3 id="playbook"><a class="header" href="#playbook">Playbook</a></h3>
<p>A blueprint of automation tasks that are executed with limited manual effort across an inventory of IT solutions. Playbooks tell Ansible what to do and how to do it. They are written in YAML and can be used to automate a wide range of tasks.</p>
<pre><code class="language-yaml">- name: Install Apache
  hosts: webservers
  become: true
  tasks:
    - name: Install Apache
      apt:
        name: apache2
        state: present
    - name: Start Apache
      service:
        name: apache2
        state: started
</code></pre>
<p><em>The above playbook will install Apache on all the hosts in the <code>webservers</code> group.</em></p>
<h3 id="task"><a class="header" href="#task">Task</a></h3>
<p>The individual steps that Ansible executes. Tasks are defined in playbooks and can be used to install packages, configure services, and more.</p>
<pre><code class="language-yaml">- name: Install Apache
  apt:
    name: apache2
    state: present
</code></pre>
<p><em>The above <code>task</code> will install <code>Apache</code> on the managed node.</em></p>
<h3 id="role"><a class="header" href="#role">Role</a></h3>
<p>A way to break down complex tasks into smaller, more manageable pieces. Roles contain lists of tasks that perform the work you’ve configured them to do.</p>
<pre><code class="language-yaml">- name: Install Apache
  hosts: webservers
  become: true
  roles:
    - apache
</code></pre>
<p><em>The above playbook will install Apache on all the hosts in the <code>webservers</code> group using the <code>apache</code> role.</em></p>
<h3 id="facts"><a class="header" href="#facts">Facts</a></h3>
<p>The way of getting data from systems. Facts can be used in playbook variables and can be disabled if not required.</p>
<pre><code class="language-yaml">- name: Gather facts
  hosts: all
  gather_facts: true
  tasks:
    - name: Print facts
      debug:
        var: ansible_facts
</code></pre>
<p><em>The above playbook will gather <code>facts</code> from all the hosts and print them.</em></p>
<h3 id="modules"><a class="header" href="#modules">Modules</a></h3>
<p>Ansible modules are standalone scripts that can be used inside playbooks to automate tasks. They are used to perform tasks such as installing packages, copying files, and managing services.</p>
<pre><code class="language-yaml">- name: Install Apache
  hosts: webservers
  become: true
  tasks:
    - name: Install Apache
      apt:
        name: apache2
        state: present
</code></pre>
<p><em>The above playbook uses the <code>apt</code> module to install <code>Apache</code> on the managed node.</em></p>
<h3 id="variables"><a class="header" href="#variables">Variables</a></h3>
<p>Ansible playbooks use a double curly brace <code>{{}}</code> syntax to reference variables. Variables can be defined in playbooks, roles, and inventory files.</p>
<pre><code class="language-yaml">- name: Informative message
  hosts: webservers
  tasks:
    - name: Hostname and port
      debug: msg="{{ ansible_hostname }} is running on port {{ apache_port }}"
</code></pre>
<p><em>The above playbook will print the value of the <code>ansible_hostname</code> and <code>apache_port</code> variables.</em></p>
<hr />
<h2 id="terraform"><a class="header" href="#terraform">Terraform</a></h2>
<p><img src="chapters/DevOps/./images/image17.png" alt="Terraform" /></p>
<p>Terraform is an infrastructure as code (IaC) tool for provisioning cloud resources. It is cloud-agnostic and allows you to define your infrastructure in a declarative configuration language.</p>
<p>Terraform then creates an execution plan that defines what will be done to reach the desired state, and then executes it to build the described infrastructure.</p>
<p>Terraform uses a declarative language called <code>HCL</code> (HashiCorp Configuration Language) to define infrastructure.</p>
<p>Terraform supports a wide range of cloud providers, the most popular being AWS, Azure, Google Cloud, and DigitalOcean.</p>
<h3 id="configuration"><a class="header" href="#configuration">Configuration</a></h3>
<p>Terraform configuration files are used to define the infrastructure that you want to create. These files are written in <code>HCL</code> and have a <code>.tf</code> extension.</p>
<pre><code class="language-hcl">provider "aws" {
  region = "us-east-1"
}

resource "aws_instance" "example" {
  ami           = "ami-0c55b159cbfafe1f0"
  instance_type = "t2.micro"
}

resource "aws_s3_bucket" "example" {
  bucket = "mybucket"
  acl    = "private"
}
</code></pre>
<p><em>The above configuration file will create an <code>EC2</code> instance and an <code>S3</code> bucket in the <code>us-east-1</code> region.</em></p>
<h3 id="commands"><a class="header" href="#commands">Commands</a></h3>
<ul>
<li>
<p><strong>terraform init</strong>: Initialize a new or existing Terraform configuration.</p>
</li>
<li>
<p><strong>terraform plan</strong>: Generate and show an execution plan.</p>
</li>
<li>
<p><strong>terraform apply</strong>: Builds or changes infrastructure according to Terraform configuration files.</p>
</li>
<li>
<p><strong>terraform destroy</strong>: Destroy the Terraform-managed infrastructure.</p>
</li>
<li>
<p><strong>terraform validate</strong>: Validates the Terraform files.</p>
</li>
<li>
<p><strong>terraform fmt</strong>: Rewrites Terraform configuration files to a canonical format.</p>
</li>
<li>
<p><strong>terraform output</strong>: Read an output from a state file.</p>
</li>
<li>
<p><strong>terraform refresh</strong>: Update local state file against real resources.</p>
</li>
</ul>
<h3 id="local-state"><a class="header" href="#local-state">Local State</a></h3>
<p>Terraform stores information about the resources it has built in a state file. This important file contains all of the data that Terraform needs to change, update, and delete infrastructure.</p>
<p>When running <code>terraform init</code>, Terraform will create a <code>.terraform</code> directory in your working directory. This directory contains the state file.</p>
<pre><code class="language-bash">terraform init    # Initialize a new or existing Terraform configuration
</code></pre>
<p><em>The above command will initialize a new or existing state file in the <code>.terraform</code> directory.</em></p>
<h3 id="remote-state"><a class="header" href="#remote-state">Remote State</a></h3>
<p>Terraform can store state files remotely, which allows you to share the state file with other team members and use it to manage infrastructure across multiple workspaces.</p>
<pre><code class="language-hcl">terraform {
  backend "s3" {
    region = "us-east-1"
    bucket = "mybucket"
    key    = "path/to/my/key"
  }
}
</code></pre>
<p><em>The above configuration will store the <code>state file</code> in an S3 bucket.</em></p>
<h3 id="plan--apply"><a class="header" href="#plan--apply">Plan / Apply</a></h3>
<p>Terraform uses a two-step process to build infrastructure. The first step is to generate an execution plan, and the second step is to apply that plan to build the infrastructure.</p>
<ol>
<li>To generate an execution plan, run the following command:</li>
</ol>
<pre><code class="language-bash">terraform plan    # Generate and show an execution plan
</code></pre>
<p>Terraform plan will show you what resources will be created, modified, or destroyed as follows:</p>
<ul>
<li>
<p><code>+</code> to indicate that a resource will be created.</p>
</li>
<li>
<p><code>-</code> to indicate that a resource will be destroyed.</p>
</li>
<li>
<p><code>~</code> to indicate that a resource will be updated.</p>
</li>
<li>
<p><code>+/-</code> to indicate that a resource will be destroyed and re-created.</p>
</li>
</ul>
<ol start="2">
<li>To apply the execution plan and build the infrastructure, run the following command:</li>
</ol>
<pre><code class="language-bash">terraform apply    # Builds or changes infrastructure according to Terraform configuration files
</code></pre>
<h3 id="terraform-variables"><a class="header" href="#terraform-variables">Terraform Variables</a></h3>
<p>Terraform variables are used to parameterize your configuration. They allow you to input data into your configuration and use it to create resources.</p>
<ul>
<li>Variables can be defined in a <code>variables.tf</code> file.</li>
</ul>
<pre><code class="language-hcl">variable "region" {
  description = "The AWS region to deploy to"
  type        = string
  default     = "us-east-1"
}
</code></pre>
<ul>
<li>Variables can be set using a <code>terraform.tfvars</code> file.</li>
</ul>
<pre><code class="language-hcl">region = "us-west-2"
</code></pre>
<ul>
<li>Variables can be used in your configuration files using the <code>var</code> keyword.</li>
</ul>
<pre><code class="language-hcl">provider "aws" {
  region = var.region
}
</code></pre>
<ul>
<li>Variables can be set via <code>command line</code>.</li>
</ul>
<pre><code class="language-bash">terraform apply -var 'region=us-west-2'
</code></pre>
<ul>
<li>Variables can be read from <code>environment variables</code>.</li>
</ul>
<pre><code class="language-bash">export TF_VAR_region=us-west-2
</code></pre>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="flutter"><a class="header" href="#flutter">Flutter</a></h1>
<hr />
<p>Coming soon...</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="infrastructure-as-code-iac"><a class="header" href="#infrastructure-as-code-iac">Infrastructure as Code (IaC)</a></h1>
<hr />
<p>Coming soon...</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="machine-learning"><a class="header" href="#machine-learning">Machine Learning</a></h1>
<hr />
<h2 id="table-of-contents-1"><a class="header" href="#table-of-contents-1">Table of Contents</a></h2>
<ul>
<li><a href="chapters/Machine_Learning/index.html#numpy">Numpy</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#what-is-numpy-array">What Is Numpy Array?</a></li>
<li><a href="chapters/Machine_Learning/index.html#list-to-numpy">List To Numpy</a></li>
<li><a href="chapters/Machine_Learning/index.html#numpy-indexing-and-slicing">NumPy Indexing and Slicing</a></li>
<li><a href="chapters/Machine_Learning/index.html#filtering">Filtering</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#pandas">Pandas</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#data-types">Data Types</a></li>
<li><a href="chapters/Machine_Learning/index.html#loc---label-based-indexing">‘loc’ - Label-Based Indexing</a></li>
<li><a href="chapters/Machine_Learning/index.html#identifying-missing-data">Identifying Missing Data</a></li>
<li><a href="chapters/Machine_Learning/index.html#filling-missing-data">Filling Missing Data</a></li>
<li><a href="chapters/Machine_Learning/index.html#groupby">GroupBy</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#matplotlib">Matplotlib</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#line-plot">Line Plot</a></li>
<li><a href="chapters/Machine_Learning/index.html#scatter-plot">Scatter Plot</a></li>
<li><a href="chapters/Machine_Learning/index.html#bar-plot">Bar Plot</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#data-processing">Data Processing</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#missing-values">Missing Values</a></li>
<li><a href="chapters/Machine_Learning/index.html#errors-and-noise">Errors and Noise</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#model-validation">Model Validation</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#training-and-test-sets">Training and Test Sets</a></li>
<li><a href="chapters/Machine_Learning/index.html#cross-validation">Cross-Validation</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#model-selection">Model Selection</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#bias-and-variance">Bias and Variance</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#supervised-learning">Supervised Learning</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#regression-and-classification-models">Regression and Classification Models</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#linear-models">Linear Models</a></li>
<li><a href="chapters/Machine_Learning/index.html#linear-models-for-regression">Linear Models For Regression</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#linear-regression">Linear Regression</a></li>
<li><a href="chapters/Machine_Learning/index.html#ridge-regression">Ridge Regression</a></li>
<li><a href="chapters/Machine_Learning/index.html#lasso-regression">Lasso Regression</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#linear-regression-accuracy-metrics">Linear Regression Accuracy Metrics</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#mean-squared-error-mse">Mean Squared Error (MSE)</a></li>
<li><a href="chapters/Machine_Learning/index.html#r%C2%B2-score-coefficient-of-determination">R² Score (Coefficient of Determination)</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#linear-models-for-classification">Linear Models For Classification</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#logistic-regression">Logistic Regression</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#linear-classification-accuracy-metrics">Linear Classification Accuracy Metrics</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#confusion-matrix">Confusion Matrix</a></li>
<li><a href="chapters/Machine_Learning/index.html#accuracy">Accuracy</a></li>
<li><a href="chapters/Machine_Learning/index.html#precision">Precision</a></li>
<li><a href="chapters/Machine_Learning/index.html#recall">Recall</a></li>
<li><a href="chapters/Machine_Learning/index.html#f1-score">F1 Score</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#decision-trees">Decision Trees</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#key-concepts">Key Concepts</a></li>
<li><a href="chapters/Machine_Learning/index.html#gini-impurity">Gini Impurity</a></li>
<li><a href="chapters/Machine_Learning/index.html#decision-tree-classification-uses-gini-impurity">Decision Tree Classification Uses Gini Impurity</a></li>
<li><a href="chapters/Machine_Learning/index.html#predicting-new-values">Predicting New Values</a></li>
<li><a href="chapters/Machine_Learning/index.html#difference-between-hyperparameter-and-parameter">Difference Between Hyperparameter and Parameter</a></li>
<li><a href="chapters/Machine_Learning/index.html#decision-tree-hyperparameter">Decision Tree Hyperparameter</a></li>
<li><a href="chapters/Machine_Learning/index.html#decision-tree-regression">Decision Tree Regression</a></li>
<li><a href="chapters/Machine_Learning/index.html#decision-tree-strengths">Decision Tree Strengths</a></li>
<li><a href="chapters/Machine_Learning/index.html#decision-tree-weakness">Decision Tree Weakness</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#random-forest">Random Forest</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#steps-to-create-a-random-forest">Steps to Create a Random Forest</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-regressor">Random Forest Regressor</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-classifier">Random Forest Classifier</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-parameters">Random Forest Parameters</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-strengths">Random Forest Strengths</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-weaknesses">Random Forest Weaknesses</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#gradient-boosted-trees">Gradient Boosted Trees</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#control-parameters">Control Parameters</a></li>
<li><a href="chapters/Machine_Learning/index.html#gradient-boosting-regressor">Gradient Boosting Regressor</a></li>
<li><a href="chapters/Machine_Learning/index.html#gradient-boosting-classifier">Gradient Boosting Classifier</a></li>
<li><a href="chapters/Machine_Learning/index.html#gradient-boosting-strengths">Gradient Boosting Strengths</a></li>
<li><a href="chapters/Machine_Learning/index.html#gradient-boosting-weaknesses">Gradient Boosting Weaknesses</a></li>
<li><a href="chapters/Machine_Learning/index.html#random-forest-vs-gradient-boosting">Random Forest vs Gradient Boosting</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#support-vector-machines-svm">Support Vector Machines (SVM)</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#hyperplane">Hyperplane</a></li>
<li><a href="chapters/Machine_Learning/index.html#types-of-kernels">Types Of Kernels</a></li>
<li><a href="chapters/Machine_Learning/index.html#svm-parameters">SVM Parameters</a></li>
<li><a href="chapters/Machine_Learning/index.html#svr-and-svc">SVR And SVC</a></li>
<li><a href="chapters/Machine_Learning/index.html#svm-strengths">SVM Strengths</a></li>
<li><a href="chapters/Machine_Learning/index.html#svm-weaknesses">SVM Weaknesses</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#determine-proximity">Determine Proximity</a></li>
<li><a href="chapters/Machine_Learning/index.html#knn-function">KNN Function</a></li>
<li><a href="chapters/Machine_Learning/index.html#knn-classifier">KNN Classifier</a></li>
<li><a href="chapters/Machine_Learning/index.html#knn-regression">KNN Regression</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#data-scaling">Data Scaling</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#standardscaler">StandardScaler</a></li>
<li><a href="chapters/Machine_Learning/index.html#robustscaler">RobustScaler</a></li>
<li><a href="chapters/Machine_Learning/index.html#minmaxscaler">MinMaxScaler</a></li>
<li><a href="chapters/Machine_Learning/index.html#normalizer">Normalizer</a></li>
</ul>
</li>
<li><a href="chapters/Machine_Learning/index.html#encoders">Encoders</a>
<ul>
<li><a href="chapters/Machine_Learning/index.html#categorical-variables">Categorical Variables</a></li>
<li><a href="chapters/Machine_Learning/index.html#onehotencoder">OneHotEncoder</a></li>
<li><a href="chapters/Machine_Learning/index.html#ordinalencoder">OrdinalEncoder</a></li>
<li><a href="chapters/Machine_Learning/index.html#simpleimputer">SimpleImputer</a></li>
<li><a href="chapters/Machine_Learning/index.html#columntransformer">ColumnTransformer</a></li>
</ul>
</li>
</ul>
<hr />
<h2 id="numpy"><a class="header" href="#numpy">Numpy</a></h2>
<p><img src="chapters/Machine_Learning/./images/image36.png" alt="Numpy" /></p>
<p>Python includes a module named numpy that can be used to store data in a matrix-like object.</p>
<p>Import statement:</p>
<pre><code class="language-python">import numpy as np
</code></pre>
<h3 id="what-is-numpy-array"><a class="header" href="#what-is-numpy-array">What Is Numpy Array?</a></h3>
<ul>
<li>A multi-dimensional array (data type = ndarray) can be created from a multi-dimensional list using the NumPy module.</li>
<li>A one-dimensional array is an array that has only one dimension and contains elements of the same type and size.</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image8.png" alt="Numpy Array" /></p>
<ul>
<li>A two-dimensional array is an array that has two dimensions and contains elements of the same type and size.</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image9.png" alt="Numpy Array" /></p>
<ul>
<li>An array has “axis/axes” to indicate its dimensions.</li>
<li>The first axis (axis = 0) of a 2-D array shows the number of rows and the second axis (axis = 1) shows the number of columns.</li>
<li>Indexing or slicing the array can be used to get or change its elements, similar to lists.</li>
</ul>
<h3 id="list-to-numpy"><a class="header" href="#list-to-numpy">List To Numpy</a></h3>
<pre><code class="language-python">list1 = [1, 2, 3, 4, 5]
arr1 = npm.array(list1)
</code></pre>
<p>This also works for multi-dimensional lists, but only if the list elements have the same type (a list with both integers and floats will be converted to all floats)</p>
<h3 id="numpy-indexing-and-slicing"><a class="header" href="#numpy-indexing-and-slicing">NumPy Indexing and Slicing</a></h3>
<ul>
<li>You can index NumPy arrays similar to lists</li>
<li>You can also slice NumPy arrays like lists</li>
</ul>
<p>For a 2-D array:</p>
<pre><code class="language-python">sub_arr = arr[start_row:end_row, start_col:end_col]
</code></pre>
<p>To access a whole row or column you can use empty slicing:</p>
<ul>
<li><code>arr[:,0]</code> for all the rows in the first column</li>
<li><code>arr[0,:]</code> for all the columns in the first row</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">arr = np.array([1,2,3,4,5,6])

print(arr[3]) #Output: 4

test1 = arr[3:]
test1[0] = 99

print(arr) # Output: [99, 5, 6]
</code></pre>
<h3 id="filtering"><a class="header" href="#filtering">Filtering</a></h3>
<p>To select array elements that meet a certain criterion, you can apply a <code>conditional expression</code>.</p>
<p>Example:</p>
<pre><code class="language-python"># Creating a NumPy array with elements -2, -1, 0, 1, and 2
arr = np.array([-2, -1, 0, 1, 2])

# Selecting and displaying only the elements in the array that are greater than 0
selected_elements = arr[arr &gt; 0] # Output: array([1, 2])
</code></pre>
<p>We could also use <code>np.where()</code>.</p>
<p>Example:</p>
<pre><code class="language-python"># Creating a NumPy array with elements -2, -1, 0, 1, and 2
arr = np.array([-2, -1, 0, 1, 2])

# Using np.where to find the indices where the elements are greater than 0
indices = np.where(arr &gt; 0)

# Selecting and displaying the elements that satisfy the condition using the obtained indices
selected_elements = arr[indices]
</code></pre>
<hr />
<h2 id="pandas"><a class="header" href="#pandas">Pandas</a></h2>
<p><img src="chapters/Machine_Learning/./images/image37.png" alt="Pandas" /></p>
<p>Pandas is a Python module used to import, export, and manipulate data.</p>
<p>import statement:</p>
<pre><code class="language-python">import pandas as pd
</code></pre>
<h3 id="data-types"><a class="header" href="#data-types">Data Types</a></h3>
<p>When data is imported using pandas, there are two different data types depending on the dimensions:</p>
<ul>
<li>1-D data is stored in a Series</li>
<li>2-D data is stored in a DataFrame</li>
<li>Each column in a DataFrame represents a Series</li>
<li>The values in each Series (data frame columns) must be the same type.</li>
</ul>
<h3 id="loc---label-based-indexing"><a class="header" href="#loc---label-based-indexing">‘loc’ - Label-Based Indexing</a></h3>
<p>The <code>loc</code> method in Pandas lets you access DataFrame data by labels or boolean array-based indexing.
Likewise, the <code>iloc</code> method lets you access DataFrame data by integer positions, like indexing elements in a Python list.</p>
<p>Example:</p>
<pre><code class="language-python"># Selecting two rows and all columns that have the index values 'ID1' and 'ID3'
df.loc[['ID1', 'ID3'], :]

# Selecting multiple rows and columns where age is greater than 30 and then selecting the 'Name' and 'Age' columns
df.loc[df['Age'] &gt; 30, ['Name', 'Age']]
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image7.png" alt="loc" /></p>
<h3 id="identifying-missing-data"><a class="header" href="#identifying-missing-data">Identifying Missing Data</a></h3>
<p>The <code>isna()</code> and <code>isnull()</code> methods are used interchangeably to check for missing values within a DataFrame or Series.</p>
<pre><code class="language-python">df.isna()

# or

df.isnull()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image1.png" alt="isna() vs isnull()" /></p>
<h3 id="filling-missing-data"><a class="header" href="#filling-missing-data">Filling Missing Data</a></h3>
<p>The <code>fillna()</code> function is a versatile tool for replacing missing or NaN (Not a Number) values within a DataFrame or Series. Available methods are <code>ffill</code> for forward filling (propagating the last valid value forward) and <code>bfill</code> for backward filling (propagating the next valid value backward).</p>
<pre><code class="language-python"># Backward fill

df.bfill()

# Forward fill

df.ffill()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image2.png" alt="bfill() vs ffill()" /></p>
<h3 id="groupby"><a class="header" href="#groupby">GroupBy</a></h3>
<p>Pandas groupby is a method that splits the dataframe into groups based on one or more columns, applies a function to each group, and combines the results into a new DataFrame.</p>
<p>Example:</p>
<pre><code class="language-python">Grouped = df.groupby('Category')

Result = Grouped.agg({'Value': ['mean', 'sum', 'count', 'max', 'min']})
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image3.png" alt="GroupBy" /></p>
<hr />
<h2 id="matplotlib"><a class="header" href="#matplotlib">Matplotlib</a></h2>
<p><img src="chapters/Machine_Learning/./images/image38.png" alt="Matplotlib" /></p>
<p>Matplotlib is a built-in module in Python used for plotting.</p>
<p>Import statement:</p>
<pre><code class="language-python">import matplotlib.pyplot

# or

import matplotlib.pyplot as plt
</code></pre>
<h3 id="line-plot"><a class="header" href="#line-plot">Line Plot</a></h3>
<p>Plots a line graph. It is commonly used for visualizing <code>continuous data</code>, like time
series or continuous functions.</p>
<pre><code class="language-python">matplotlib.pyplot.plot()

# or

plt.plot()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image4.png" alt="Line Plot" /></p>
<h3 id="scatter-plot"><a class="header" href="#scatter-plot">Scatter Plot</a></h3>
<p>Scatter plots are used to visualize the relationship between two numerical variables, allowing you to <code>identify patterns, trends, clusters, correlations, and outliers</code>.</p>
<pre><code class="language-python">matplotlib.pyplot.scatter()

# or

plt.scatter()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image5.png" alt="Scatter Plot" /></p>
<h3 id="bar-plot"><a class="header" href="#bar-plot">Bar Plot</a></h3>
<p>Bar plots are used to compare the values of different categories, display frequencies or counts of categorical variables, and visualize the relationship between categorical and numerical variables. <code>Useful for comparing discrete data</code>.</p>
<pre><code class="language-python">matplotlib.pyplot.bar()

# or

plt.bar()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image6.png" alt="Bar Plot" /></p>
<hr />
<h2 id="data-processing"><a class="header" href="#data-processing">Data Processing</a></h2>
<p>If your dataset is based on real-life data, it might not be perfect.</p>
<p>Your dataset might include:</p>
<ul>
<li>Missing values</li>
<li>Erroneous measurements</li>
<li>Noise</li>
</ul>
<h3 id="missing-values"><a class="header" href="#missing-values">Missing Values</a></h3>
<h4 id="how-to-find-missing-values-in-a-pandas-dataframe"><a class="header" href="#how-to-find-missing-values-in-a-pandas-dataframe">How to Find Missing Values in a Pandas DataFrame</a></h4>
<ul>
<li>Check the data type for each column using <code>df.dtypes</code>. If a column has invalid data points, such as empty strings or non-numeric values, the data type will be object.</li>
<li>You can either manually change the data type for all the columns using <code>df.astype()</code> or replace the invalid points with NaN using <code>df.replace()</code>.</li>
<li>Once all the columns are the proper data type, you can count the number of NaN values using one of these methods:</li>
</ul>
<p>Other usefull functions are:</p>
<pre><code class="language-python">df.isnull().sum()

# or

df.isna().sum()

# or

df.info()
</code></pre>
<h4 id="what-to-do-with-missing-values"><a class="header" href="#what-to-do-with-missing-values">What to Do with Missing Values?</a></h4>
<p>Pandas offers several built-in functions to deal with missing values in different ways.</p>
<ul>
<li>You can choose to remove the rows or columns that contain NaN values.</li>
<li>Yu can replace them with a specific value or a calculated value based on the rest of the data.</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image13.png" alt="Missing Values" /></p>
<h4 id="dropping-nan-values"><a class="header" href="#dropping-nan-values">Dropping NaN Values</a></h4>
<p>Dropping values is easy with a Series, as you can drop the values individually. For DataFrame, it is a bit more complicated as you can not have an uneven number of rows.</p>
<ul>
<li>You can drop any row or drop any column that has at least one NaN value (based on the specified axis).</li>
<li>You can use the <code>how</code> or <code>thresh</code> keywords to specify the number of NaN values that must exist before you drop the row or column.</li>
</ul>
<h4 id="filling-nan-values"><a class="header" href="#filling-nan-values">Filling NaN Values</a></h4>
<ul>
<li><strong>Forward-fill</strong>: Use the previous valid value to fill the missing value, which
can be useful for time series data.</li>
</ul>
<pre><code class="language-python">df.ffill()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image10.png" alt="ffill()" /></p>
<ul>
<li><strong>Back-fill**</strong>: Use the next valid value to fill the missing value, which can be
useful for reverse time series data.</li>
</ul>
<pre><code class="language-python">df.bfill()
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image11.png" alt="bfill()" /></p>
<ul>
<li><strong>Custom code</strong>: Write your own logic to fill the missing values, which can
be useful for complex or specific cases.</li>
</ul>
<pre><code class="language-python">df.interpolate(method='linear')
</code></pre>
<p><img src="chapters/Machine_Learning/./images/image12.png" alt="interpolate()" /></p>
<h3 id="errors-and-noise"><a class="header" href="#errors-and-noise">Errors and Noise</a></h3>
<h4 id="detecting-errors-in-real-measurements"><a class="header" href="#detecting-errors-in-real-measurements">Detecting Errors in Real Measurements</a></h4>
<ul>
<li>To identify potential outliers, you can use different methods depending on the data's characteristics and shape, such as visualizing or analyzing them statistically.</li>
<li>After finding the errors, you can handle them in the same way as you handled the NaN values. A simple way to code this is to change all the incorrect values to <code>np.nan</code> and then use your preferred method to replace the missing values.</li>
</ul>
<hr />
<h2 id="model-validation"><a class="header" href="#model-validation">Model Validation</a></h2>
<h3 id="training-and-test-sets"><a class="header" href="#training-and-test-sets">Training and Test Sets</a></h3>
<ul>
<li>
<p><strong>Training Set</strong>: The training set is the largest part of the dataset and the foundation for model building. Machine learning algorithms use this segment to learn from the data’s patterns.</p>
</li>
<li>
<p><strong>Test Set</strong>: Different from the training set, the test set serves as an unbiased measure for evaluating the model’s performance on completely new and unseen data.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
</code></pre>
<p><em>The code snippet above shows how to use the <code>train_test_split</code> function to split the dataset into training and test sets.</em></p>
<p><img src="chapters/Machine_Learning/./images/image14.png" alt="Train and test" /></p>
<h3 id="cross-validation"><a class="header" href="#cross-validation">Cross-Validation</a></h3>
<p>Cross-validation is a technique to evaluate the performance of a machine learning model on <code>unseen data</code>.</p>
<p>Example:</p>
<p>If 𝒌 = 𝟑, then the data set <code>{𝑥1, 𝑥2, 𝑥3, 𝑥4, 𝑥5, 𝑥6}</code> is divided into
three subsets:</p>
<ul>
<li><code>{𝑥1, 𝑥2}</code></li>
<li><code>{𝑥3, 𝑥4}</code></li>
<li><code>{𝑥5, 𝑥6}</code></li>
</ul>
<pre><code class="language-python">from sklearn.cross_validation import cross_val_score

cross_val_score(model, X, y, cv=3)
</code></pre>
<p><em>The code snippet above shows how to use the <code>cross_val_score</code> function to evaluate the performance of a model.</em></p>
<p><img src="chapters/Machine_Learning/./images/image15.png" alt="Cross-Validation" /></p>
<p>Compute the mean (average) test error across the three folds.</p>
<hr />
<h2 id="model-selection"><a class="header" href="#model-selection">Model Selection</a></h2>
<h3 id="bias-and-variance"><a class="header" href="#bias-and-variance">Bias and Variance</a></h3>
<ul>
<li>
<p><strong>Bias</strong>: The difference between the model's predicted value and the actual value. <code>High bias</code> model tend to <code>underfit</code> the data, meaning they cannot capture the complexity or patterns in the data.</p>
</li>
<li>
<p><strong>Variance</strong>: The sensitivity of the model to changes in the training data. <code>High variance</code> models tend to <code>overfit</code> the data, meaning they cannot generalize well to new or unseen data.</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image16.png" alt="Bias and Variance" /></p>
<hr />
<h2 id="supervised-learning"><a class="header" href="#supervised-learning">Supervised Learning</a></h2>
<p>Supervised learning is a type of machine learning that learns labeled data, which consists of input/output pairs. The input can be either a <code>numerical value (regression)</code> or a <code>class (classification)</code>. Supervised learning aims to make accurate predictions for new data that has not been seen before.</p>
<h3 id="regression-and-classification-models"><a class="header" href="#regression-and-classification-models">Regression and Classification Models</a></h3>
<p>Classification and regression are two types of supervised machine learning
problems, where the goal is to learn a mapping function from input variables
to output variables.</p>
<ul>
<li>
<p>In <strong>classification</strong>, we want to assign a discrete label to an input, such as
"spam" or "not spam" for an email.</p>
</li>
<li>
<p>In <strong>regression</strong>, we want to estimate a continuous value for an input, such as
the price of a house based on its features.</p>
</li>
</ul>
<hr />
<h2 id="linear-models"><a class="header" href="#linear-models">Linear Models</a></h2>
<p>Linear models are supervised learning algorithms that predict an output variable based on a <code>linear combination of input features</code>. They can be used for both regression and classification tasks, depending on whether the output variable is continuous or binary.</p>
<hr />
<h2 id="linear-models-for-regression"><a class="header" href="#linear-models-for-regression">Linear Models For Regression</a></h2>
<p>For regression, the general prediction formula for a linear model looks like this:</p>
<p><img src="chapters/Machine_Learning/./images/image26.png" alt="Linear Model" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>y^</code> is the predicted value.</p>
</li>
<li>
<p><code>b</code> is the bias term.</p>
</li>
<li>
<p><code>w</code> is the weight vector.</p>
</li>
<li>
<p><code>x</code> is the input feature vector.</p>
</li>
</ul>
<p>Popular linear models used for regression include:</p>
<ul>
<li>
<p><strong><em>Linear Regression</em></strong></p>
</li>
<li>
<p><strong><em>Ridge Regression</em></strong></p>
</li>
<li>
<p><strong><em>Lasso Regression</em></strong></p>
</li>
</ul>
<h3 id="linear-regression"><a class="header" href="#linear-regression">Linear Regression</a></h3>
<ul>
<li>
<p>Also known as <code>Ordinary Least Squares (OLS)</code>.</p>
</li>
<li>
<p>This is the simplest linear method for regression.</p>
</li>
<li>
<p>Linear regression finds the parameters <code>w</code> and <code>b</code> the mean squared error between predictions, <code>y^</code>, and the true values, <code>y</code>, for the training set.</p>
</li>
<li>
<p>The <code>mean squared error</code> is the sum of the squared differences between the
predictions and the true values, divided by the number of samples.</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image27.png" alt="Mean Squared Error" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>N</code> is the number of samples.</p>
</li>
<li>
<p><code>y^[i] = w[0] * x[i][0] + b</code></p>
</li>
<li>
<p><code>y[i]</code> is the true value.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.linear_model import LinearRegression

# Instantiate the regressor
lr = LinearRegression()

# Fit the regressor to the data
lr.fit(X, y)

# Predict the labels of the test set
y_pred = lr.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>linear regression model</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image28.png" alt="Linear Regression" /></p>
<h3 id="ridge-regression"><a class="header" href="#ridge-regression">Ridge Regression</a></h3>
<ul>
<li>
<p>It is also a linear model for regression, so it uses the same formula as linear regression.</p>
</li>
<li>
<p>For ridge regression, the coefficients <code>w</code> are chosen not only so that they predict well on the training data, but also to fit an additional constraint.</p>
</li>
<li>
<p>The additional constraint is that the magnitude of the coefficients must be as small as possible; all entries of <code>w</code> should be close to zero, called <code>L2 regularization</code>.</p>
</li>
<li>
<p>The square of the <code>L2 norm</code> of the <code>w</code> is defined as:</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image29.png" alt="L2 Norm" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>α</code> is a hyperparameter that controls the amount of regularization applied to the coefficients of a linear model. The larger the value, the more aggressive the penalization is. It can be any real value between o and infinity.</p>
</li>
<li>
<p>Regularization means explicitly restricting a model to avoid over-fitting.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.linear_model import Ridge

# Instantiate the regressor
ridge = Ridge(alpha=0.1, normalize=True)

# Fit the regressor to the data
ridge.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = ridge.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>ridge regression model</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image30.png" alt="Ridge Regression" /></p>
<h3 id="lasso-regression"><a class="header" href="#lasso-regression">Lasso Regression</a></h3>
<ul>
<li>
<p>Alternative to ridge regression for regularizing linear regression.</p>
</li>
<li>
<p>The lasso regression restricts the coefficients to be close to zero, but in a slightly different way, called <code>L1 regularization</code>.</p>
</li>
<li>
<p>The <code>L1 norm</code> of the <code>w</code> is defined as:</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image31.png" alt="L1 Norm" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>α</code> is the regularization parameter.</p>
</li>
<li>
<p>The consequence of L1 regularization is that when using the lasso, some
coefficients are exactly zero.</p>
</li>
<li>
<p>This means some features are entirely ignored by the model.</p>
</li>
<li>
<p>This can be seen as a form of automatic feature selection.</p>
</li>
<li>
<p>Can reveal the most important features in the model.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.linear_model import Lasso

# Instantiate the regressor
lasso = Lasso(alpha=0.1, normalize=True)

# Fit the regressor to the data
lasso.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = lasso.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>lasso regression model</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image32.png" alt="Lasso Regression" /></p>
<hr />
<h2 id="linear-regression-accuracy-metrics"><a class="header" href="#linear-regression-accuracy-metrics">Linear Regression Accuracy Metrics</a></h2>
<ul>
<li>
<p><strong><em>Mean Squared Error (MSE)</em></strong></p>
</li>
<li>
<p><strong><em>R² score (Coefficient of Determination)</em></strong></p>
</li>
</ul>
<h3 id="mean-squared-error-mse"><a class="header" href="#mean-squared-error-mse">Mean Squared Error (MSE)</a></h3>
<p>The Mean Squared Error (MSE) is a fundamental metric used to quantify the goodness of fit of a regression model by measuring the average squared difference between the predicted values, <code>y^</code>, and the actual values, <code>y</code>, of the dependent variable.</p>
<p><img src="chapters/Machine_Learning/./images/image35.png" alt="Mean Squared Error" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>N</code> is the number of datapoints in the dataset.</p>
</li>
<li>
<p><code>y[i]</code> signifies the actual value of the dependent variable for the i-th data point.</p>
</li>
<li>
<p><code>y^[i]</code> corresponds to the predicted value of the dependent variable for the i-th data point based on the regression model.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error

# Compute the mean squared error of the regressor
mse = mean_squared_error(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>mean squared error</code> to evaluate the performance of a regression model.</em></p>
<h3 id="r²-score-coefficient-of-determination"><a class="header" href="#r²-score-coefficient-of-determination">R² Score (Coefficient of Determination)</a></h3>
<ol>
<li>R-squared is the ration of the explained variation to the total variation in the dependent variable.</li>
</ol>
<p><img src="chapters/Machine_Learning/./images/image33.png" alt="R² Score" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>RSS</code> is the residual sum of squares.</p>
</li>
<li>
<p><code>TSS</code> is the total sum of squares.</p>
</li>
</ul>
<ol start="2">
<li>R-squared can also be expressed as the square of the correlation coefficient, which measures the strength and direction of the linear relationship between two variables.</li>
</ol>
<p><img src="chapters/Machine_Learning/./images/image34.png" alt="R² Score" /></p>
<p>Where:</p>
<ul>
<li><code>r</code> is the correlation coefficient.</li>
</ul>
<ol start="3">
<li>R-squared can be negative if the model fits worse than a horizontal line, which is the simplest model that uses the mean of the dependent variable as a constant prediction.</li>
</ol>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import r2_score

# Compute the R² score of the regressor
r2 = r2_score(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>R² score</code> to evaluate the performance of a regression model.</em></p>
<hr />
<h2 id="linear-models-for-classification"><a class="header" href="#linear-models-for-classification">Linear Models For Classification</a></h2>
<p>For classification, the general prediction formula for a linear model looks like this:</p>
<p><img src="chapters/Machine_Learning/./images/image39.png" alt="Linear Model" /></p>
<p>Where:</p>
<ul>
<li>
<p><code>x</code> is the input feature vector.</p>
</li>
<li>
<p><code>w</code> is the weight vector.</p>
</li>
<li>
<p><code>b</code> is the bias term.</p>
</li>
<li>
<p><code>p(x)</code> is the probability that the input <code>x</code> belongs to the positive class.</p>
</li>
</ul>
<p>Some popular linear models used for classification include:</p>
<ul>
<li>
<p><strong><em>Logistic Regression</em></strong></p>
</li>
<li>
<p><strong><em>Support Vector Machines (SVM)</em></strong></p>
</li>
</ul>
<h3 id="logistic-regression"><a class="header" href="#logistic-regression">Logistic Regression</a></h3>
<ul>
<li>
<p>Primarily used for <strong>classification</strong>, not regression, despite its name.</p>
</li>
<li>
<p>It’s a statistical model used to predict the probability of a binary outcome, typically denoted as class 0 and class 1.</p>
</li>
<li>
<p>The logistic regression model estimates the probability that a given input
belongs to one of these two classes.</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image40.png" alt="Logistic Regression" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.linear_model import LogisticRegression

# Instantiate the classifier
logreg = LogisticRegression()

# Fit the classifier to the data
logreg.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = logreg.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>logistic regression model</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image41.png" alt="Logistic Regression" /></p>
<hr />
<h2 id="linear-classification-accuracy-metrics"><a class="header" href="#linear-classification-accuracy-metrics">Linear Classification Accuracy Metrics</a></h2>
<ul>
<li>
<p><strong><em>Confusion Matrix</em></strong></p>
</li>
<li>
<p><strong><em>Accuracy</em></strong></p>
</li>
<li>
<p><strong><em>Precision</em></strong></p>
</li>
<li>
<p><strong><em>Recall</em></strong></p>
</li>
<li>
<p><strong><em>F1 Score</em></strong></p>
</li>
</ul>
<h3 id="confusion-matrix"><a class="header" href="#confusion-matrix">Confusion Matrix</a></h3>
<p>A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known.</p>
<ul>
<li><strong>True Positives (TP)</strong>: The number of instances that are actually positive (P) and are correctly predicted as positive by the classification algorithm.</li>
<li><strong>False Positives (FP)</strong>: The number of instances that are actually negative (N) but are incorrectly predicted as positive (P) by the algorithm.</li>
<li><strong>True Negatives (TN)</strong>: The number of instances that are actually negative (N) and are correctly predicted as negative by the algorithm.</li>
<li><strong>False Negatives (FN)</strong>: The number of instances that are actually positive (P) but are incorrectly predicted as negative (N) by the algorithm.</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image17.png" alt="Confusion Matrix" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import confusion_matrix

# Compute the confusion matrix of the classifier
cm = confusion_matrix(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use a <code>confusion matrix</code> to evaluate the performance of a classification model.</em></p>
<h3 id="accuracy"><a class="header" href="#accuracy">Accuracy</a></h3>
<p>Accuracy is a metric that quantifies the ratio of correctly classified instances to
the total predictions made by a model.</p>
<p><img src="chapters/Machine_Learning/./images/image18.png" alt="Accuracy" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import accuracy_score

# Compute the accuracy of the classifier
accuracy = accuracy_score(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>accuracy</code> metric to evaluate the performance of a classification model.</em></p>
<h3 id="precision"><a class="header" href="#precision">Precision</a></h3>
<p>Precision is a metric that measures the accuracy of <code>positive predictions</code> generated
by a model, taking <code>false positives</code> into account.</p>
<p><img src="chapters/Machine_Learning/./images/image19.png" alt="Precision" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import precision_score

# Compute the precision of the classifier
precision = precision_score(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>precision</code> metric to evaluate the performance of a classification model.</em></p>
<h3 id="recall"><a class="header" href="#recall">Recall</a></h3>
<p>Recall, also known as sensitivity or the true positive rate, quantifies a model’s
capacity to identify all positive instances, even when considering false negatives.</p>
<p><img src="chapters/Machine_Learning/./images/image20.png" alt="Recall" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import recall_score

# Compute the recall of the classifier
recall = recall_score(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>recall</code> metric to evaluate the performance of a classification model.</em></p>
<h3 id="f1-score"><a class="header" href="#f1-score">F1 Score</a></h3>
<p>The F1-Score presents a harmonious equilibrium between precision and recall,
while accounting for both false positives and false negatives.</p>
<p><img src="chapters/Machine_Learning/./images/image21.png" alt="F1 Score" /></p>
<p>Example:</p>
<pre><code class="language-python">from sklearn.metrics import f1_score

# Compute the F1 score of the classifier
f1 = f1_score(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>F1 score</code> to evaluate the performance of a classification model.</em></p>
<hr />
<h2 id="decision-trees"><a class="header" href="#decision-trees">Decision Trees</a></h2>
<p><img src="chapters/Machine_Learning/./images/image22.png" alt="Decision Trees" /></p>
<p>Decision trees are widely used models for classification and regression tasks. They learn a hierarchy of if/else questions, leading to a decision.</p>
<h3 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h3>
<ul>
<li>
<p>The top of the decision tree is referred to as the root node.</p>
</li>
<li>
<p>A leaf node is a node that has no children. A node that does have children is known as an internal node.</p>
</li>
<li>
<p>Nodes in a tree are leveled by their distance from the root (level 0). The tree’s height is the maximum level of any node.</p>
</li>
</ul>
<h3 id="gini-impurity"><a class="header" href="#gini-impurity">Gini Impurity</a></h3>
<p>The Gini impurity is a measure of how likely a randomly chosen element from a set would be incorreclty labeled if it was randomly labeled according to the distribution of labels in the set.</p>
<p><img src="chapters/Machine_Learning/./images/image23.png" alt="Gini Impurity" /></p>
<p>Where <strong><em>k</em></strong> is the number of classes in <strong><em>pi</em></strong> is the probability of choosing an element of class <strong><em>i</em></strong>. The Gini impurity ranges from <code>0</code> to <code>0.5</code>.</p>
<ul>
<li>
<p><code>0</code> means the set is <strong>perfectly pure</strong> (all the elements belong to the same class).</p>
</li>
<li>
<p><code>0.5</code> means the set is <strong>completely impure</strong> (equal probability of choosing any class).</p>
</li>
</ul>
<h3 id="decision-tree-classification-uses-gini-impurity"><a class="header" href="#decision-tree-classification-uses-gini-impurity">Decision Tree Classification Uses Gini Impurity</a></h3>
<ul>
<li>
<p>To use Gini in decision tree classification, the algorithm compares the Gini values of different possible splits and chooses the one that minimizes the Gini value.</p>
</li>
<li>
<p>This means that the algorithm tries to find the best feature and the best threshold to divide the data into two subsets, such that the subsets are more pure than the original node.</p>
</li>
<li>
<p>The algorithm repeats this process recursively until all the nodes are pure or some stopping criteria are met.</p>
</li>
</ul>
<h3 id="predicting-new-values"><a class="header" href="#predicting-new-values">Predicting New Values</a></h3>
<ul>
<li>
<p>A prediction on a new data point is made by checking which region of the partition the point lies in and then assigning the majority target (or the single target in the case of pure leaves) in that region to the predicted value.</p>
</li>
<li>
<p>The region can be found by traversing the tree from the root and going left or right, depending on whether the test is fulfilled or not.</p>
</li>
</ul>
<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier(max_depth=2, random_state=0)

# Fit the classifier to the data
dtc.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = dtc.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>decision tree classifier</code> to predict the labels of the test set.</em></p>
<h3 id="difference-between-hyperparameter-and-parameter"><a class="header" href="#difference-between-hyperparameter-and-parameter">Difference Between Hyperparameter and Parameter</a></h3>
<ul>
<li>
<p><strong>Hyperparameter</strong>: It’s a configuration setting for the model. Its value is set prior to the commencement of the learning process and is not learned from the data.</p>
</li>
<li>
<p><strong>Parameters</strong>: It’s an internal variable of a model. Its value is learned from the
data during the training process.</p>
</li>
</ul>
<h3 id="decision-tree-hyperparameter"><a class="header" href="#decision-tree-hyperparameter">Decision Tree Hyperparameter</a></h3>
<ul>
<li>
<p><strong>max_depth</strong>: This hyperparameter controls the maximum depth of the three.</p>
</li>
<li>
<p><strong>min_samples_split</strong>: This hyperparameter dictates the minimum number of sample required to split an internal node. By increasing this value, the tree becomes more constrained as it has to consider more samples at each node, making it harder for the model to fit to noise in the training data.</p>
</li>
<li>
<p><strong>min_samples_leaf</strong>: This is the minimum number of samples required to be at a leaf node. This hyperparameter prevents the model from learning very specific patterns from the training data.</p>
</li>
<li>
<p><strong>max_features</strong>: The number of features to consider when looking for the best split. By reducing the number of features considered at each split, we can add randomness to the model making it more robust to noise.</p>
</li>
</ul>
<p>Example:</p>
<pre><code class="language-python">from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier(max_depth=None, max_leaf_nodes=5, random_state=0)

# Fit the classifier to the data
y_pred = dtc.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = dtc.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>decision tree classifier</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image24.png" alt="Decision Tree" /></p>
<h3 id="decision-tree-regression"><a class="header" href="#decision-tree-regression">Decision Tree Regression</a></h3>
<ul>
<li>
<p>Decision trees can also be used for regression.</p>
</li>
<li>
<p>Splits are evaluated based on Mean Squared Error (MSE) instead of Gini impurity.</p>
</li>
<li>
<p>Subsequent levels result in reduced mean squared error.</p>
</li>
</ul>
<pre><code class="language-python">from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Instantiate the regressor
dtr = DecisionTreeRegressor(criterion='squared_error', splitter='best', max_leaf_nodes= 2)

# Fit the regressor to the data
_ = dtr.fit(X, y)

# Predict the labels of the test set
y_hat = dtr.predict(X[X[:, 1] &lt;= 1.067])

# Compute the mean squared error of the regressor
mse = metrics.mean_squared_error(y_hat, y[X[:, 1] &lt;= 1.067])
</code></pre>
<p><em>The code snippet above shows how to use a <code>decision tree regressor</code> to predict the labels of the test set and compute the <code>mean squared error</code> of the regressor.</em></p>
<h3 id="decision-tree-strengths"><a class="header" href="#decision-tree-strengths">Decision Tree Strengths</a></h3>
<ul>
<li>
<p>As each feature is processed separately, no pre-processing like normalization or standardization of features is needed.</p>
</li>
<li>
<p>Decision trees work well when you have features that are on
completely different scales, or a mix of binary and continuous
features.</p>
</li>
<li>
<p>The resulting model can easily be visualized and understood by
non-experts (at least for smaller trees).</p>
</li>
</ul>
<h3 id="decision-tree-weakness"><a class="header" href="#decision-tree-weakness">Decision Tree Weakness</a></h3>
<ul>
<li>Even with the use of pre-pruning, decision tree models tend to over-fit and provide poor generalization performance.</li>
</ul>
<hr />
<h2 id="random-forest"><a class="header" href="#random-forest">Random Forest</a></h2>
<p><img src="chapters/Machine_Learning/./images/image25.png" alt="Random Forest" /></p>
<p>A Random Forest is essentially a collection of Decision Trees, where every tree is slightly different from the others. The idea behind random forests is that each tree might do a relatively good job of predicting, but might over-fit on part of the data.</p>
<h3 id="steps-to-create-a-random-forest"><a class="header" href="#steps-to-create-a-random-forest">Steps to Create a Random Forest</a></h3>
<ol>
<li>
<p>Select the number of trees to use (hyperparameter is <strong><em>n_estimators</em></strong>).</p>
</li>
<li>
<p>Random forests get their name from injecting randomness into the tree building to ensure each tree is different. There are two ways in which the trees in a random forest are randomized:</p>
</li>
</ol>
<ul>
<li>
<p><strong>Select Random Data Points</strong>:</p>
<ul>
<li>
<p>For each tree, a <strong>bootstrap sample</strong> is created.</p>
</li>
<li>
<p>A bootstrap sample is the same size as the original data, but contains a random assortment of the data, where some of the data samples are missing (approx. 1/3) and some data samples are repeated.</p>
</li>
<li>
<p>A decision tree is then made using the bootstrap sample.</p>
</li>
</ul>
</li>
</ul>
<pre><code class="language-python">from sklearn.utils import resample

# Create a bootstrap sample
bootstrap_sample = resample(X_train, y_train, replace=True, random_state=0)
</code></pre>
<p><em>The code snippet above shows how to create a <code>bootstrap sample</code> using the <code>resample</code> function.</em></p>
<ul>
<li>
<p><strong>Select Random Features</strong>:</p>
<ul>
<li>
<p>the algorithm randomly selects a <strong>subset of the features</strong>, and it looks for the best possible test involving one of these features.</p>
</li>
<li>
<p>The number of features that are selected is controlled by the <strong><em>max_features</em></strong> parameter.</p>
</li>
<li>
<p>This selection of a subset of features is repeated separately in each node, so that each node in the tree splits the dataset using a different subset of the features.</p>
</li>
<li>
<p>A <strong>high <em>max_features</em></strong> value means that the trees in the random forest will be very similar, but they will be able to fit the data easily, using the most distinctive features.</p>
</li>
<li>
<p>A <strong>low <em>max_features</em></strong> value means that the trees in the random forest will be quite different, but that each tree might need to be very deep to fit the data well.</p>
</li>
</ul>
</li>
</ul>
<h3 id="random-forest-regressor"><a class="header" href="#random-forest-regressor">Random Forest Regressor</a></h3>
<p>For regression, we can average the results to get our final prediction.</p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestRegressor

# Instantiate the regressor
rfr = RandomForestRegressor(n_estimators=4, random_state=0, max_leaf_nodes=3)

# Fit the regressor to the data
rfr.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = rfr.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>random forest regressor</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image42.png" alt="Random Forest Regressor" /></p>
<h3 id="random-forest-classifier"><a class="header" href="#random-forest-classifier">Random Forest Classifier</a></h3>
<p>For classification, each algorithm makes a "soft" prediction, providing a probability of each possible output label. The probabilities predicted by all the trees are averaged, and the class with the highest probability is the final prediction.</p>
<pre><code class="language-python">from sklearn.ensemble import RandomForestClassifier

# Instantiate the classifier
rfc = RandomForestClassifier(n_estimators=4, random_state=0, max_leaf_nodes=3)

# Fit the classifier to the data
rfc.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = rfc.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>random forest classifier</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image43.png" alt="Random Forest Classifier" /></p>
<h3 id="random-forest-parameters"><a class="header" href="#random-forest-parameters">Random Forest Parameters</a></h3>
<ul>
<li>
<p><strong><em>random_state</em></strong>: Setting this variable is important for reproducibility.</p>
</li>
<li>
<p><strong><em>max_features</em></strong>: Determines how random each tree is</p>
</li>
<li>
<p><strong><em>n_estimators</em></strong>: Larger is always better. Averaging more trees will yield a more robust ensemble by reducing over-fitting.</p>
</li>
</ul>
<h3 id="random-forest-strengths"><a class="header" href="#random-forest-strengths">Random Forest Strengths</a></h3>
<ul>
<li>
<p>Random forests share all the benefits of decision trees.</p>
</li>
<li>
<p>They are very powerful, often work well without heavy tuning of the parameters, and don’t require scaling of the data.</p>
</li>
<li>
<p>Random forests for regression and classification are currently among the most widely used machine learning methods.</p>
</li>
</ul>
<h3 id="random-forest-weaknesses"><a class="header" href="#random-forest-weaknesses">Random Forest Weaknesses</a></h3>
<ul>
<li>
<p>Random forests require more memory and are slower to train and predict than linear models.</p>
</li>
<li>
<p>Random forests don’t tend to perform well on very high dimensional, sparse data, such as text data.</p>
</li>
</ul>
<hr />
<h2 id="gradient-boosted-trees"><a class="header" href="#gradient-boosted-trees">Gradient Boosted Trees</a></h2>
<p><img src="chapters/Machine_Learning/./images/image44.png" alt="Gradient Boosted Trees" /></p>
<p>Gradient boosting works by iteratively training the weak learners on gradient-based functions and incorporating them into the model as <strong><em>boosted</em></strong> participants.</p>
<ul>
<li>At its core, gradient boosting works by combining multiple gradient steps to build up a strong predicting model from weak estimators residing in a gradient function space with additional weak learners joining the gradient function space after each iteration of gradient boosting.</li>
</ul>
<h3 id="control-parameters"><a class="header" href="#control-parameters">Control Parameters</a></h3>
<ul>
<li>
<p><strong><em>n_estimators</em></strong>: The number of trees created.</p>
</li>
<li>
<p><strong><em>learning_rate</em></strong>: Controls how strongly each tree tries to correct after the previous one.</p>
</li>
</ul>
<h3 id="gradient-boosting-regressor"><a class="header" href="#gradient-boosting-regressor">Gradient Boosting Regressor</a></h3>
<pre><code class="language-python">from sklearn.ensemble import GradientBoostingRegressor

# Instantiate the regressor
gbr = GradientBoostingRegressor(n_estimators=100, random_state=0, learning_rate=0.1)

# Fit the regressor to the data
gbr.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = gbr.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>gradient boosting regressor</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image45.png" alt="Gradient Boosting Regressor" /></p>
<h3 id="gradient-boosting-classifier"><a class="header" href="#gradient-boosting-classifier">Gradient Boosting Classifier</a></h3>
<pre><code class="language-python">from sklearn.ensemble import GradientBoostingClassifier

# Instantiate the classifier
gbc = GradientBoostingClassifier(n_estimators=100, random_state=0, learning_rate=0.1)

# Fit the classifier to the data
gbc.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = gbc.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>gradient boosting classifier</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image46.png" alt="Gradient Boosting Classifier" /></p>
<h3 id="gradient-boosting-strengths"><a class="header" href="#gradient-boosting-strengths">Gradient Boosting Strengths</a></h3>
<ul>
<li>Gradient boosted decision trees are among the most powerful and widely used models for supervised learning.</li>
</ul>
<h3 id="gradient-boosting-weaknesses"><a class="header" href="#gradient-boosting-weaknesses">Gradient Boosting Weaknesses</a></h3>
<ul>
<li>
<p>Their main drawback is that they require careful tuning of the parameters and may take a long time to train.</p>
</li>
<li>
<p>As with other tree-based models, it often does not work well on high-dimensional sparse data.</p>
</li>
</ul>
<h3 id="random-forest-vs-gradient-boosting"><a class="header" href="#random-forest-vs-gradient-boosting">Random Forest vs Gradient Boosting</a></h3>
<ul>
<li>
<p>As both gradient boosting and random forests perform well on similar kinds of data, a common approach is to first try random forests.</p>
</li>
<li>
<p>If random forests work well but prediction time is at a premium, or it’s important to squeeze out that last percentage of accuracy from the machine learning model, moving to gradient boosting often helps.</p>
</li>
</ul>
<hr />
<h2 id="support-vector-machines-svm"><a class="header" href="#support-vector-machines-svm">Support Vector Machines (SVM)</a></h2>
<p><img src="chapters/Machine_Learning/./images/image47.png" alt="Support Vector Machines" /></p>
<p>In Support Vector Machines (SVM), support vectors are the data points that lie closest to the decision boundary (or hyperplane). They are the data points most difficult to classify and have direct influence on the optimal location of the decision boundary.</p>
<h3 id="hyperplane"><a class="header" href="#hyperplane">Hyperplane</a></h3>
<p>A hyperplane is a plane with one less dimension than the dimension of its ambient space. For example, if space is 3-dimensional, then its hyperplanes are 2-dimensional planes. Moreover, if the space is 2-dimensional, its hyperplanes are the 1-dimensional lines.</p>
<p><img src="chapters/Machine_Learning/./images/image48.png" alt="Hyperplane" /></p>
<pre><code class="language-python">from sklearn.svm import SVC
import numpy as np

# Instantiate the classifier
svc = SVC(kernel='linear')

# Fit the classifier to the data
svc.fit(X_train, y_train)

# Get the support vectors
support_vectors = svc.support_vectors_

# Get the coefficients and the intercept
coefficients = svc.coef_
intercept = svc.intercept_

# Get the margin
margin = 2 / np.linalg.norm(coefficients)
</code></pre>
<p><em>The code snippet above shows how to use a <code>support vector classifier</code> to fit the data and get the support vectors, coefficients, intercept, and margin.</em></p>
<h3 id="types-of-kernels"><a class="header" href="#types-of-kernels">Types Of Kernels</a></h3>
<ul>
<li>
<p><strong>Linear Kernel</strong>: The linear kernel is simply the dot product of the vectors. It is the most common kernel used in SVM.</p>
</li>
<li>
<p><strong>Polynomial Kernel</strong>: For a polynomial kernel, we calculate the dot product and raise it to the power of d (degree of the polynomial), 𝛾 is the slope, and 𝑐0 is the constant. It is not as preferred as other kernel functions as it is less efficient and accurate.</p>
</li>
<li>
<p><strong>Radial Basis Function (RBF)</strong> or Gaussian Kernel: The RBF kernel uses the Euclidean distance between the two vectors. It is one of the most preferred kernels in SVM. Usually chosen for non-linear data.</p>
</li>
<li>
<p><strong>Sigmoid Kernel</strong>: The sigmoid kernel applies the sigmoid function to the dot product. It is preferred for neural networks.</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image49.png" alt="Kernels" /></p>
<h3 id="svm-parameters"><a class="header" href="#svm-parameters">SVM Parameters</a></h3>
<ul>
<li>
<p><strong>C</strong>: The regularization parameter. The strength of the regularization is inversely proportional to C.</p>
</li>
<li>
<p><strong>Gamma</strong>: The gamma parameter determines how far the influence of a single training example reaches, with low values corresponding to a far reach, and high values to a limited reach.</p>
</li>
<li>
<p><strong>Epsilon</strong>: <em>Used just for SVR model</em>. It specifies the epsilon-tube within which no penalty is associated in the training loss function with points predicted within a distance epsilon from the actual value.</p>
</li>
</ul>
<h3 id="svr-and-svc"><a class="header" href="#svr-and-svc">SVR And SVC</a></h3>
<ul>
<li>
<p><strong>Support Vector Regression (SVR)</strong> is a type of Support Vector Machine (SVM) that uses the same principles but for prediction of a continuous outcome. It fits the best line or curve to a set of data points.</p>
</li>
<li>
<p><strong>Support Vector Classification (SVC)</strong> is a type of Support Vector Machine (SVM) that uses the same principles but for prediction of a categorical outcome. It creates a boundary between different categories.</p>
</li>
</ul>
<pre><code class="language-python">from sklearn.svm import SVR
from sklearn.svm import SVC

# Instantiate the regressor and the classifier
svr = SVR(kernel='linear', C=1.0, epsilon=0.1)
svc = SVC(kernel='rbf', C=1.0, gamma=0.1)

# Fit the regressor and the classifier to the data
svr.fit(X_train, y_train)
svc.fit(X_train, y_train)

# Predict the labels of the test set
y_pred_svr = svr.predict(X_test)
y_pred_svc = svc.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>support vector regressor</code> and a <code>support vector classifier</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image50.png" alt="Support Vector Machines" /></p>
<h3 id="svm-strengths"><a class="header" href="#svm-strengths">SVM Strengths</a></h3>
<ul>
<li>
<p>Kernelized support vector machines are powerful models and perform well on a variety of datasets.</p>
</li>
<li>
<p>SVMs work well on low-dimensional and high-dimensional data.</p>
</li>
</ul>
<h3 id="svm-weaknesses"><a class="header" href="#svm-weaknesses">SVM Weaknesses</a></h3>
<ul>
<li>
<p>SVMs don’t scale very well with the number of samples.</p>
</li>
<li>
<p>They require careful pre-processing of the data and tuning of the parameters.</p>
</li>
</ul>
<hr />
<h2 id="k-nearest-neighbors-knn"><a class="header" href="#k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)</a></h2>
<p><img src="chapters/Machine_Learning/./images/image51.png" alt="K-Nearest Neighbors" /></p>
<p>K-nearest neighbors (K-NN) predicts the classification of new data sample(s) depending on the proximity of the new data sample(s) to the existing data.</p>
<p>K represents the number of neighbors considered to determine the label for the new data sample.</p>
<p>The predicted label is based on a voting method, so an odd number of neighbors is preferred to ensure there are no ties.</p>
<h3 id="determine-proximity"><a class="header" href="#determine-proximity">Determine Proximity</a></h3>
<ul>
<li>
<p><strong>Euclidean Distance</strong>: The most common distance measure. It is the square root of the sum of the squared differences between the two vectors.</p>
</li>
<li>
<p><strong>Manhattan Distance</strong>: The sum of the absolute differences between the two vectors.</p>
</li>
<li>
<p><strong>Minkowski Distance</strong>: A generalization of the Euclidean and Manhattan distances.</p>
</li>
</ul>
<h3 id="knn-function"><a class="header" href="#knn-function">KNN Function</a></h3>
<pre><code class="language-python">sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights='uniform', p=2, metric='minkowski')
</code></pre>
<p>Where:</p>
<ul>
<li>
<p><strong>n_neighbors</strong>: The number of neighbors to consider.</p>
</li>
<li>
<p><strong>weights</strong>: The weight function used in prediction. The default is <code>uniform</code>, which means all points in each neighborhood are weighted equally. The other option is <code>distance</code>, where closer neighbors will be weighted higher than neighbors further away.</p>
</li>
<li>
<p><strong>p</strong>: When <code>p = 1</code>, this is equivalent to using the Manhattan distance, and when <code>p = 2</code>, which is the default, this is equivalent to using the Euclidean distance. For arbitrary <code>p</code>, this is equivalent to using the Minkowski distance.</p>
</li>
<li>
<p><strong>metric</strong>: The distance metric to use for the tree. The default is <code>minkowski</code>, and other options include <code>manhattan</code> and <code>euclidean</code>.</p>
</li>
</ul>
<h3 id="knn-classifier"><a class="header" href="#knn-classifier">KNN Classifier</a></h3>
<ul>
<li>
<p><strong>Smoother</strong>: With a larger <code>K</code>, each prediction is the average of more points, so each
individual point has less influence on the outcome. This results in a smoother model with less variance, as the predictions are less sensitive to fluctuations in the training data.</p>
</li>
<li>
<p><strong>More Biased</strong>: A larger <code>K</code> means the algorithm is considering more neighbors, some of which may be quite far away from the query point in the feature space. This could lead to predictions that are biased and less accurate.</p>
</li>
</ul>
<pre><code class="language-python">from sklearn.neighbors import KNeighborsClassifier

# Instantiate the classifier
knn = KNeighborsClassifier(n_neighbors=5)

# Fit the classifier to the data
knn.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = knn.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>K-nearest neighbors classifier</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image53.png" alt="K-Nearest Neighbors" /></p>
<pre><code class="language-python">from sklearn.metrics import confusion_matrix

# Compute the confusion matrix of the classifier
cm = confusion_matrix(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use a <code>confusion matrix</code> to evaluate the performance of a classification model.</em></p>
<p><img src="chapters/Machine_Learning/./images/image52.png" alt="K-Nearest Neighbors" /></p>
<h3 id="knn-regression"><a class="header" href="#knn-regression">KNN Regression</a></h3>
<p>k-NN regression is a non-parametric algorithm that predicts continuous variables by averaging the output values of the k most similar instances in the training data.</p>
<p>The choice of k and the distance metric affects the model’s performance. A smaller <code>K</code> makes the model more flexible but more prone to noise. A larger <code>K</code> makes the model smoother but more biased.</p>
<pre><code class="language-python">from sklearn.neighbors import KNeighborsRegressor

# Instantiate the regressor
knn = KNeighborsRegressor(n_neighbors=5)

# Fit the regressor to the data
knn.fit(X_train, y_train)

# Predict the labels of the test set
y_pred = knn.predict(X_test)
</code></pre>
<p><em>The code snippet above shows how to use a <code>K-nearest neighbors regressor</code> to predict the labels of the test set.</em></p>
<p><img src="chapters/Machine_Learning/./images/image54.png" alt="K-Nearest Neighbors" /></p>
<pre><code class="language-python">from sklearn.metrics import mean_squared_error

# Compute the mean squared error of the regressor
mse = mean_squared_error(y_test, y_pred)
</code></pre>
<p><em>The code snippet above shows how to use the <code>mean squared error</code> to evaluate the performance of a regression model.</em></p>
<p><img src="chapters/Machine_Learning/./images/image55.png" alt="K-Nearest Neighbors" /></p>
<hr />
<h2 id="data-scaling"><a class="header" href="#data-scaling">Data Scaling</a></h2>
<p><img src="chapters/Machine_Learning/./images/image59.png" alt="Data Scaling" /></p>
<p>Data scaling is a crucial step in the preprocessing of data for machine learning models. It is the process of normalizing the range of features of the data. It is generally performed during the data preprocessing step.</p>
<p>The non-linear algorithms, such as K-Nearest Neighbors, Support Vector Machines, and Neural Networks, are sensitive to the scale of the input data.</p>
<h3 id="standardscaler"><a class="header" href="#standardscaler">StandardScaler</a></h3>
<p>Standard Scaler is a technique for transforming numerical data to have a <strong><em>mean of zero</em></strong> and a <strong><em>standard deviation of one</em></strong>.</p>
<p>It is useful for machine learning algorithms that perform better when the input variables are scaled to a standard range.</p>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler

# Instantiate the scaler
scaler = StandardScaler()

# Fit and transform the data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>StandardScaler</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image56.png" alt="StandardScaler" /></p>
<h3 id="robustscaler"><a class="header" href="#robustscaler">RobustScaler</a></h3>
<p>Robust Scaler is a technique for transforming numerical data to have a <strong><em>median of zero</em></strong> and a <strong><em>interquartile range of one</em></strong>.</p>
<p>This method is particularly useful when you have data that has outliers. It's a way to standardize your data that is robust to outliers.</p>
<pre><code class="language-python">from sklearn.preprocessing import RobustScaler

# Instantiate the scaler
scaler = RobustScaler()

# Fit and transform the data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>RobustScaler</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image57.png" alt="RobustScaler" /></p>
<h3 id="minmaxscaler"><a class="header" href="#minmaxscaler">MinMaxScaler</a></h3>
<p>The MinMaxScaler is a data normalization technique used in machine learning preprocessing. It scales each feature to a given range, usually between <strong><em>0</em></strong> and <strong><em>1</em></strong>.</p>
<p>This scaling method is beneficial when you want your data to be bounded within a certain range. However, it’s important to note that MinMaxScaler does not reduce the impact of outliers.</p>
<pre><code class="language-python">from sklearn.preprocessing import MinMaxScaler

# Instantiate the scaler
scaler = MinMaxScaler()

# Fit and transform the data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>MinMaxScaler</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image58.png" alt="MinMaxScaler" /></p>
<h3 id="normalizer"><a class="header" href="#normalizer">Normalizer</a></h3>
<p>Each feature (or data sample) with at least one non-zero component is rescaled independently of other features (or samples) so that its norm (vector length) equals one</p>
<p>It scales each row of the data to unit norm. This means that for each row in your data, it calculates the norm (based on the type of norm you specify - <code>l1</code>, <code>l2</code>, or <code>max</code>), and then divides each element in the row by this norm.</p>
<pre><code class="language-python">from sklearn.preprocessing import Normalizer

# Instantiate the scaler (the norm parameter can be 'l1', 'l2', or 'max')
scaler = Normalizer(norm='l2')

# Fit and transform the data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>Normalizer</code> method to transform the data.</em></p>
<hr />
<h2 id="encoders"><a class="header" href="#encoders">Encoders</a></h2>
<h3 id="categorical-variables"><a class="header" href="#categorical-variables">Categorical Variables</a></h3>
<p>A categorical variable, also known as a qualitative variable, is a type of variable that can assume a set number of distinct categories or groups.</p>
<p>Each category represents a qualitative characteristic or attribute. The categories are mutually exclusive, meaning an observation can only belong to one category.</p>
<p>Categorical variables come in two types: <code>nominal</code> and <code>ordinal</code>.</p>
<ul>
<li>
<p><strong>Nominal variables</strong> consist of categories that lack any inherent order, such as the color of a car (red, blue, green, etc.).</p>
</li>
<li>
<p><strong>Ordinal variables</strong> contain categories that have a natural order or ranking, like educational level (high school, bachelor's, master's, Ph.D.).</p>
</li>
</ul>
<p><img src="chapters/Machine_Learning/./images/image60.png" alt="Categorical Variables" /></p>
<h3 id="onehotencoder"><a class="header" href="#onehotencoder">OneHotEncoder</a></h3>
<p>One hot encoding is a technique to convert categorical variables into numerical values for machine learning models.</p>
<p>It creates a new column for each category and assigns a binary value of <strong>1</strong> or <strong>0</strong> to indicate the presence or absence of that category.</p>
<pre><code class="language-python">from sklearn.preprocessing import OneHotEncoder

# Instantiate the encoder
encoder = OneHotEncoder(sparse_output=False, dtype="int")

# Fit and transform the data
X_train_encoded = encoder.fit_transform(X_train)

# Transform the test data
X_test_encoded = encoder.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>OneHotEncoder</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image61.png" alt="One-Hot Encoding" /></p>
<h3 id="ordinalencoder"><a class="header" href="#ordinalencoder">OrdinalEncoder</a></h3>
<p>Ordinal encoding is a technique that transforms categorical variables into numerical values by assigning a unique integer to each category.</p>
<p>This is useful when the categories have some inherent order or ranking, such as low, medium and high.</p>
<p>Ordinal encoding can also reduce the dimensionality of the data and make it easier for some algorithms to handle.</p>
<pre><code class="language-python">from sklearn.preprocessing import OrdinalEncoder

# Instantiate the encoder
encoder = OrdinalEncoder()

# Fit and transform the data
X_train_encoded = encoder.fit_transform(X_train)

# Transform the test data
X_test_encoded = encoder.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>OrdinalEncoder</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image62.png" alt="Ordinal Encoding" /></p>
<h3 id="simpleimputer"><a class="header" href="#simpleimputer">SimpleImputer</a></h3>
<p>SimpleImputer can replace missing values with a constant value, or with a statistic (such as mean, median, or mode) calculated from each column. The choice of strategy depends on the type and distribution of the data, as well as the goal of the analysis.</p>
<p>Imputation strategies include:</p>
<ul>
<li>
<p><strong>mean</strong>: Replace missing values using the mean along each column.</p>
</li>
<li>
<p><strong>median</strong>: Replace missing values using the median along each column.</p>
</li>
<li>
<p><strong>most_frequent</strong>: Replace missing using the most frequent value along each column.</p>
</li>
<li>
<p><strong>constant</strong>: Replace missing values with a constant value.</p>
</li>
</ul>
<pre><code class="language-python">from sklearn.impute import SimpleImputer

# Instantiate the imputer
imputer = SimpleImputer(strategy='mean')

# Fit and transform the data
X_train_imputed = imputer.fit_transform(X_train)

# Transform the test data
X_test_imputed = imputer.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>SimpleImputer</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image63.png" alt="SimpleImputer" /></p>
<h3 id="columntransformer"><a class="header" href="#columntransformer">ColumnTransformer</a></h3>
<p>The ColumnTransformer class allows you to apply different transformations to different columns in the input data.</p>
<p>This is incredibly useful, since continuous and categorical features need very different kinds of preprocessing.</p>
<pre><code class="language-python">from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer

# Define transformers and preprocessor
ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])
onehot_encoder = OneHotEncoder(sparse_output = False)
imputer = SimpleImputer(strategy='mean')

# Instantiate the ColumnTransformer
preprocessor = ColumnTransformer(
  transformers=[('ordinal', ordinal_encoder, ['Quality']),
                ('onehot', onehot_encoder, ['Fruit']),
                ('imputer', imputer, ['Weight'])],
  remainder='passthrough' # Pass through any other columns not specified
)

# Fit and transform the data
X_train_preprocessed = preprocessor.fit_transform(X_train)

# Transform the test data
X_test_preprocessed = preprocessor.transform(X_test)
</code></pre>
<p><em>The code snippet above shows how to use the <code>ColumnTransformer</code> method to transform the data.</em></p>
<p><img src="chapters/Machine_Learning/./images/image64.png" alt="ColumnTransformer" /></p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="software-architecture"><a class="header" href="#software-architecture">Software Architecture</a></h1>
<hr />
<h2 id="table-of-contents-2"><a class="header" href="#table-of-contents-2">Table of Contents</a></h2>
<ul>
<li><a href="chapters/Software_Architecture/index.html#abstraction">Abstraction</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#decomposition">Decomposition</a></li>
<li><a href="chapters/Software_Architecture/index.html#coupling">Coupling</a></li>
<li><a href="chapters/Software_Architecture/index.html#cohesion">Cohesion</a></li>
<li><a href="chapters/Software_Architecture/index.html#agile-driven">Agile-Driven</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#styles">Styles</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#layered">Layered</a></li>
<li><a href="chapters/Software_Architecture/index.html#mvc-model-view-controller">MVC (Model, View, Controller)</a></li>
<li><a href="chapters/Software_Architecture/index.html#pipeline">Pipeline</a></li>
<li><a href="chapters/Software_Architecture/index.html#microkernel">Microkernel</a></li>
<li><a href="chapters/Software_Architecture/index.html#service-based">Service-Based</a></li>
<li><a href="chapters/Software_Architecture/index.html#event-driven">Event-Driven</a></li>
<li><a href="chapters/Software_Architecture/index.html#other-architectures">Other Architectures</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#data-management">Data Management</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#pdca-for-data-governance">PDCA For Data Governance</a></li>
<li><a href="chapters/Software_Architecture/index.html#dimensions-of-data-quality">Dimensions of Data Quality</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#data-modeling">Data Modeling</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#database-models">Database Models</a></li>
<li><a href="chapters/Software_Architecture/index.html#normalizing-a-relational-database">Normalizing A Relational Database</a></li>
<li><a href="chapters/Software_Architecture/index.html#components-of-a-dbms">Components Of A DBMS</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#software-development-life-cycle">Software Development Life Cycle</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#delivery-cycles">Delivery Cycles</a></li>
<li><a href="chapters/Software_Architecture/index.html#planning">Planning</a></li>
<li><a href="chapters/Software_Architecture/index.html#requirements-gathering--analysis">Requirements Gathering &amp; Analysis</a></li>
<li><a href="chapters/Software_Architecture/index.html#design">Design</a></li>
<li><a href="chapters/Software_Architecture/index.html#implementation">Implementation</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#software-development-patterns">Software Development Patterns</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#model-view-controller-mvc">Model-View-Controller (MVC)</a></li>
<li><a href="chapters/Software_Architecture/index.html#solid-principles">SOLID Principles</a></li>
</ul>
</li>
<li><a href="chapters/Software_Architecture/index.html#cloud-computing">Cloud Computing</a>
<ul>
<li><a href="chapters/Software_Architecture/index.html#essential-characteristics">Essential Characteristics</a></li>
<li><a href="chapters/Software_Architecture/index.html#resource">Resource</a></li>
<li><a href="chapters/Software_Architecture/index.html#scaling">Scaling</a></li>
<li><a href="chapters/Software_Architecture/index.html#service-models">Service Models</a></li>
<li><a href="chapters/Software_Architecture/index.html#deployment-models">Deployment Models</a></li>
</ul>
</li>
</ul>
<hr />
<h2 id="abstraction"><a class="header" href="#abstraction">Abstraction</a></h2>
<p>High-level representation or simplification of complex systems, design or structures.</p>
<p><img src="chapters/Software_Architecture/./images/image1.png" alt="Abstraction" /></p>
<h3 id="decomposition"><a class="header" href="#decomposition">Decomposition</a></h3>
<p>Segregation is the idea of breaking down large entities into into smaller and more specialized ones. Create more modular, maintainable, and flexible software designs.</p>
<h4 id="poor-decomposition"><a class="header" href="#poor-decomposition">Poor Decomposition</a></h4>
<ul>
<li>Customer class is responsible for all entities.</li>
<li>Customer class is responsible for all operations.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image2.png" alt="Poor decomposition" /></p>
<h4 id="improved-decomposition"><a class="header" href="#improved-decomposition">Improved Decomposition</a></h4>
<ul>
<li>Customer class is responsible for representing customer to access information.</li>
<li>CustomerManager class is responsible for dealing with customer-related operations.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image3.png" alt="Improved decomposition" /></p>
<h3 id="coupling"><a class="header" href="#coupling">Coupling</a></h3>
<p>Coupling is the density of dependencies among classes. If a class changes and there is high coupling, many other classes will need to change as well.</p>
<h4 id="tight-coupling"><a class="header" href="#tight-coupling">Tight Coupling</a></h4>
<ul>
<li>Customer class creates an Order object directly within its method.</li>
<li>Order class maintains a direct reference to the Customer object (customer attribute).</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image4.png" alt="Tight coupling" /></p>
<h4 id="loose-coupling"><a class="header" href="#loose-coupling">Loose Coupling</a></h4>
<ul>
<li>Order class no longer directly references the Customer class.</li>
<li>Customer information (name and email) referred as parameters with methods get() and set().</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image5.png" alt="Loose coupling" /></p>
<h3 id="cohesion"><a class="header" href="#cohesion">Cohesion</a></h3>
<p>Cohesion is the degree of unity or closeness among the elements within a class. Each component should represent a single concept. All logic/data of the component should be directly applicable to the concept.</p>
<h4 id="low-cohesion"><a class="header" href="#low-cohesion">Low Cohesion</a></h4>
<ul>
<li>Customer mixing responsibilities with createOrder and sendEmail.</li>
<li>Order mixing responsabilities with calculateTotal and sendConfirmationEmail.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image6.png" alt="Low cohesion" /></p>
<h4 id="high-cohesion"><a class="header" href="#high-cohesion">High Cohesion</a></h4>
<ul>
<li>Order class no longer directly references the Customer class.</li>
<li>Customer information (name and email) referred as parameters with methods get() and set().</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image7.png" alt="High cohesion" /></p>
<h3 id="agile-driven"><a class="header" href="#agile-driven">Agile-Driven</a></h3>
<p>Architectural approach aligns with the principles and values of agile methodologies. Agile approach emphasizes flexibility, collaboration and responsiveness to change.</p>
<p><img src="chapters/Software_Architecture/./images/image8.png" alt="Agile-Driven" /></p>
<hr />
<h2 id="styles"><a class="header" href="#styles">Styles</a></h2>
<p>Recurring patterns used in organizing the structure and components of a software system. Choosing the right architecture style is a critical decision that influences various aspects of software development.</p>
<h3 id="layered"><a class="header" href="#layered">Layered</a></h3>
<p>Each layer provides a specific functionalities and services to the layers above it.</p>
<p>Key characteristics:</p>
<ul>
<li>Simplicity</li>
<li>Modularity</li>
<li>Maintainability</li>
<li>Separation of Concerns.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image9.png" alt="Layered" /></p>
<h3 id="mvc-model-view-controller"><a class="header" href="#mvc-model-view-controller">MVC (Model, View, Controller)</a></h3>
<p>Separate the concerns of data management, user interface and application logic.</p>
<p>Key characteristics:</p>
<ul>
<li>Separation of concerns</li>
<li>User interaction</li>
<li>Loose coupling</li>
<li>Layered-Oriented</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image10.png" alt="MVC" /></p>
<h4 id="model"><a class="header" href="#model">Model</a></h4>
<p>Encapsulates the data and provides methods to manipulate and access data.</p>
<h4 id="view"><a class="header" href="#view">View</a></h4>
<p>Represents the user interface elements and visual components.</p>
<h4 id="controller"><a class="header" href="#controller">Controller</a></h4>
<p>Handles user input, processes requests, and updates the Model accordingly.</p>
<h3 id="pipeline"><a class="header" href="#pipeline">Pipeline</a></h3>
<p>Structures the processing of data or tasks as a series of connected processing stages.</p>
<p>Key characteristics:</p>
<ul>
<li>Sequential</li>
<li>Modularity</li>
<li>Parallelism</li>
<li>Isolation</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image11.png" alt="Pipeline" /></p>
<h3 id="microkernel"><a class="header" href="#microkernel">Microkernel</a></h3>
<p>Structure by separating the core functionality (microkernel) from additional services and functionalities.</p>
<p>Key characteristics:</p>
<ul>
<li>Flexibility</li>
<li>Modularity</li>
<li>Reduced complexity</li>
<li>Portability</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image12.png" alt="Microkernel" /></p>
<h3 id="service-based"><a class="header" href="#service-based">Service-Based</a></h3>
<p>Structures an application as a collection independently deployable services.</p>
<p>Key characteristics:</p>
<ul>
<li>Loose coupling</li>
<li>Interoperability</li>
<li>Independently deployable</li>
<li>Reusability</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image13.png" alt="Service-Based" /></p>
<h3 id="event-driven"><a class="header" href="#event-driven">Event-Driven</a></h3>
<p>The system flow is determined by events, such as user actions, messages from other systems.</p>
<p>Key characteristics:</p>
<ul>
<li>Events</li>
<li>Responsiveness</li>
<li>Communication</li>
<li>Scalability</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image14.png" alt="Event Driven" /></p>
<h3 id="other-architectures"><a class="header" href="#other-architectures">Other Architectures</a></h3>
<ul>
<li>Space-Based</li>
<li>Orchestration-Driven Service-Oriented</li>
<li>Microservices</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image15.png" alt="Others" /></p>
<hr />
<h2 id="data-management"><a class="header" href="#data-management">Data Management</a></h2>
<p><img src="chapters/Software_Architecture/./images/image16.png" alt="Data Management" /></p>
<ul>
<li>
<p>Data Stewardship</p>
</li>
<li>
<p>Data Quality</p>
</li>
<li>
<p>Data Integration</p>
</li>
<li>
<p>Enterprise Perspectives</p>
</li>
<li>
<p>Culture Change Leadership</p>
</li>
</ul>
<h3 id="pdca-for-data-governance"><a class="header" href="#pdca-for-data-governance">PDCA For Data Governance</a></h3>
<ul>
<li>
<p><strong>Plan</strong>: Establish a plan to solve data issue problems and determine cost and effort.</p>
</li>
<li>
<p><strong>Do</strong>: Implement data quality controls and processes.</p>
</li>
<li>
<p><strong>Check</strong>: Continuous monitoring and measurement of data quality.</p>
</li>
<li>
<p><strong>Act</strong>: Identify data quality issues and take corrective actions.</p>
</li>
</ul>
<h3 id="dimensions-of-data-quality"><a class="header" href="#dimensions-of-data-quality">Dimensions of Data Quality</a></h3>
<ul>
<li>
<p><strong>Accuracy</strong>: Data is correct and reliable.</p>
</li>
<li>
<p><strong>Completeness</strong>: Data is not missing any information.</p>
</li>
<li>
<p><strong>Consistency</strong>: Data is consistent across the organization.</p>
</li>
<li>
<p><strong>Currency</strong>: Data is up-to-date and relevant.</p>
</li>
<li>
<p><strong>Precision</strong>: Data is precise and accurate.</p>
</li>
<li>
<p><strong>Privacy</strong>: Data is secure and private.</p>
</li>
<li>
<p><strong>Reasonableness</strong>: Data is reasonable and logical.</p>
</li>
<li>
<p><strong>Timeliness</strong>: Data is available when needed.</p>
</li>
<li>
<p><strong>Uniqueness</strong>: Data is unique and not duplicated.</p>
</li>
<li>
<p><strong>Validity</strong>: Data is valid and conforms to business rules.</p>
</li>
</ul>
<hr />
<h2 id="data-modeling"><a class="header" href="#data-modeling">Data Modeling</a></h2>
<ul>
<li>
<p><strong>Database</strong>: A collection of related data that can be stored in a central location or in multiple locations.</p>
</li>
<li>
<p><strong>Data Hierarchy</strong>: The structure and organization of data, which involves fields, records, and tables.</p>
</li>
<li>
<p><strong>Database Management System (DBMS)</strong>: Software for creating, storing, maintaining, and accessing database files.</p>
</li>
</ul>
<h3 id="database-models"><a class="header" href="#database-models">Database Models</a></h3>
<p><img src="chapters/Software_Architecture/./images/image17.png" alt="Database Models" /></p>
<ul>
<li>
<p><strong>Conceptual Model</strong>: High-level view of the entities and their attributes.</p>
</li>
<li>
<p><strong>Logical Model</strong>: Detailed view of the entities and the relationships between them.</p>
</li>
<li>
<p><strong>Physical Model</strong>: Detailed view of the entities, their attributes, and the relationships between them.</p>
</li>
</ul>
<h3 id="normalizing-a-relational-database"><a class="header" href="#normalizing-a-relational-database">Normalizing A Relational Database</a></h3>
<ul>
<li>
<p>Eliminate duplicated fields from the same table.</p>
</li>
<li>
<p>Create separate tables for each group of related data.</p>
</li>
<li>
<p>Identify each record with a unique field (primary key).</p>
</li>
</ul>
<h3 id="components-of-a-dbms"><a class="header" href="#components-of-a-dbms">Components Of A DBMS</a></h3>
<ul>
<li>
<p><strong>Database Engine</strong>: Translates logical requests to physical ones</p>
</li>
<li>
<p><strong>Data Definition</strong>: Create / maintain data dictionary</p>
</li>
<li>
<p><strong>Data Manipulation</strong>: SQL or QBE</p>
</li>
<li>
<p><strong>Application Generation</strong>: Design applications or parts of them</p>
</li>
<li>
<p><strong>Data Administration</strong>: Security (CRUD), recovery, backup</p>
</li>
</ul>
<hr />
<h2 id="software-development-life-cycle"><a class="header" href="#software-development-life-cycle">Software Development Life Cycle</a></h2>
<p><img src="chapters/Software_Architecture/./images/image18.png" alt="SDLC" /></p>
<p>Software development life cycle (SDLC) is a series of well-defined phases performed in sequence that serves as a framework for developing a system or project.</p>
<h3 id="delivery-cycles"><a class="header" href="#delivery-cycles">Delivery Cycles</a></h3>
<ul>
<li>
<p>Predictive</p>
</li>
<li>
<p>Iterative</p>
</li>
<li>
<p>Incremental</p>
</li>
<li>
<p>Agile</p>
</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image19.png" alt="Delivery Cycles" /></p>
<h3 id="planning"><a class="header" href="#planning">Planning</a></h3>
<ol>
<li>
<p>Economic feasibility</p>
</li>
<li>
<p>Technical feasibility</p>
</li>
<li>
<p>Operational feasibility</p>
</li>
<li>
<p>Schedule feasibility</p>
</li>
<li>
<p>Legal feasibility</p>
</li>
</ol>
<h3 id="requirements-gathering--analysis"><a class="header" href="#requirements-gathering--analysis">Requirements Gathering &amp; Analysis</a></h3>
<p>Requirements are documented and tracked in a requirements traceability matrix (RTM).</p>
<p><img src="chapters/Software_Architecture/./images/image20.png" alt="Requirements Gathering" /></p>
<h3 id="design"><a class="header" href="#design">Design</a></h3>
<ul>
<li>
<p><strong>Conceptual</strong>: The output of analysis.</p>
</li>
<li>
<p><strong>Logical</strong>: Adds a hardware / software / OS layer.</p>
</li>
<li>
<p><strong>Physical</strong>: Specific platform design.</p>
</li>
</ul>
<h3 id="implementation"><a class="header" href="#implementation">Implementation</a></h3>
<ul>
<li>
<p><strong>Coding</strong>: Writing the code.</p>
</li>
<li>
<p><strong>Testing</strong>: Testing the code.</p>
</li>
<li>
<p><strong>Deployment</strong>: Deploying the code.</p>
</li>
</ul>
<hr />
<h2 id="software-development-patterns"><a class="header" href="#software-development-patterns">Software Development Patterns</a></h2>
<p>Patterns are reusable solutions to common problems in software design. From a solution design perspective different patterns exist to solve different problems.</p>
<ul>
<li>
<p>Creational Patterns</p>
</li>
<li>
<p>Structural Patterns</p>
</li>
<li>
<p>Behavioral Patterns</p>
</li>
</ul>
<h3 id="model-view-controller-mvc"><a class="header" href="#model-view-controller-mvc">Model-View-Controller (MVC)</a></h3>
<p><img src="chapters/Software_Architecture/./images/image10.png" alt="MVC" /></p>
<ul>
<li>Model</li>
</ul>
<p>The model manages the behavior and data of the application domain, responds to requests for information about its state (usually from the view), and responds to instructions to change state (usually from the controller).</p>
<ul>
<li>View</li>
</ul>
<p>The view manages the display of information.</p>
<ul>
<li>Controller</li>
</ul>
<p>The controller interprets the mouse and keyboard inputs from the user, informing the model and/or the view of change as appropriate.</p>
<h3 id="solid-principles"><a class="header" href="#solid-principles">SOLID Principles</a></h3>
<p><img src="chapters/Software_Architecture/./images/image21.png" alt="SOLID" /></p>
<ul>
<li>
<p><strong>S - Single Responsibility Principle</strong>: A class should have only one reason to change.</p>
</li>
<li>
<p><strong>O - Open/Closed Principle</strong>: A class should be open for extension, but closed for modification.</p>
</li>
<li>
<p><strong>L - Liskov Substitution Principle</strong>: Objects in a program should be replaceable with instances of their subtypes without altering the correctness of that program.</p>
</li>
<li>
<p><strong>I - Interface Segregation Principle</strong>: Software modules (classes and methods) should not be forced to depend upon interfaces that they do not use.</p>
</li>
<li>
<p><strong>D - Dependency Inversion Principle</strong>: High-level modules should not depend on low-level modules. Both should depend on abstractions.</p>
</li>
</ul>
<hr />
<h2 id="cloud-computing"><a class="header" href="#cloud-computing">Cloud Computing</a></h2>
<p><img src="chapters/Software_Architecture/./images/image22.png" alt="Cloud Computing" /></p>
<p>Cloud computing is a model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage,
applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. This cloud model is composed of five essential characteristics, three service models, and four deployment models.</p>
<h3 id="essential-characteristics"><a class="header" href="#essential-characteristics">Essential Characteristics</a></h3>
<ul>
<li>
<p>On-demand</p>
</li>
<li>
<p>Ubiquitous access</p>
</li>
<li>
<p>Multitenancy (and resource pooling)</p>
</li>
<li>
<p>Elasticity</p>
</li>
<li>
<p>Measured usage</p>
</li>
</ul>
<h3 id="resource"><a class="header" href="#resource">Resource</a></h3>
<p>An IT resource is a physical or virtual IT related artifact that can be either software based, such as a virtual server or a custom software program, or hardware based, such as a physical server or a network device.</p>
<p><img src="chapters/Software_Architecture/./images/image23.png" alt="Resource" /></p>
<h3 id="scaling"><a class="header" href="#scaling">Scaling</a></h3>
<ul>
<li><strong>Horizontal Scaling</strong>: Adding more nodes to a system.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image24.png" alt="Horizontal Scaling" /></p>
<ul>
<li><strong>Vertical Scaling</strong>: Adding more resources to a single node.</li>
</ul>
<p><img src="chapters/Software_Architecture/./images/image25.png" alt="Vertical Scaling" /></p>
<h3 id="service-models"><a class="header" href="#service-models">Service Models</a></h3>
<p><img src="chapters/Software_Architecture/./images/image26.png" alt="Service Models" /></p>
<h3 id="deployment-models"><a class="header" href="#deployment-models">Deployment Models</a></h3>
<p><img src="chapters/Software_Architecture/./images/image27.png" alt="Deployment Models" /></p>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="software-testing"><a class="header" href="#software-testing">Software Testing</a></h1>
<hr />
<h2 id="table-of-contents-3"><a class="header" href="#table-of-contents-3">Table of Contents</a></h2>
<ul>
<li><a href="chapters/Software_Testing/index.html#foundations-of-testing">Foundations of Testing</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#test-case--test-suite">Test Case &amp; Test Suite</a></li>
<li><a href="chapters/Software_Testing/index.html#types-of-test-activities">Types of Test Activities</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#software-testing-life-cycle-stlc">Software Testing Life Cycle (STLC)</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#requirements-analysis">Requirements Analysis</a></li>
<li><a href="chapters/Software_Testing/index.html#test-planning">Test Planning</a></li>
<li><a href="chapters/Software_Testing/index.html#test-case-development">Test Case Development</a></li>
<li><a href="chapters/Software_Testing/index.html#environment-setup">Environment Setup</a></li>
<li><a href="chapters/Software_Testing/index.html#test-execution">Test Execution</a></li>
<li><a href="chapters/Software_Testing/index.html#test-cycle-closure">Test Cycle Closure</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#unit-testing">Unit Testing</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#characteristics">Characteristics</a></li>
<li><a href="chapters/Software_Testing/index.html#what-to-test">What to test?</a></li>
<li><a href="chapters/Software_Testing/index.html#when-to-test">When to test?</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#junit">JUnit</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#terminology">Terminology</a></li>
<li><a href="chapters/Software_Testing/index.html#junit-test-class">JUnit Test Class</a></li>
<li><a href="chapters/Software_Testing/index.html#junit-test-suite">JUnit Test Suite</a></li>
<li><a href="chapters/Software_Testing/index.html#junit-test-runner">JUnit Test Runner</a></li>
<li><a href="chapters/Software_Testing/index.html#junit-5">JUnit 5</a></li>
<li><a href="chapters/Software_Testing/index.html#annotations">Annotations</a></li>
<li><a href="chapters/Software_Testing/index.html#ignoring-a-test">Ignoring a Test</a></li>
<li><a href="chapters/Software_Testing/index.html#timeouts">Timeouts</a></li>
<li><a href="chapters/Software_Testing/index.html#expected-exceptions">Expected Exceptions</a></li>
<li><a href="chapters/Software_Testing/index.html#data-driven-testing">Data Driven Testing</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#dependencies-using-doubles">Dependencies Using Doubles</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#stubs">Stubs</a></li>
<li><a href="chapters/Software_Testing/index.html#test-lifecycle-with-stubs">Test Lifecycle with Stubs</a></li>
<li><a href="chapters/Software_Testing/index.html#mocks">Mocks</a></li>
<li><a href="chapters/Software_Testing/index.html#test-lifecycle-with-mocks">Test Lifecycle with Mocks</a></li>
<li><a href="chapters/Software_Testing/index.html#mockito">Mockito</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#black-box-testing">Black Box Testing</a>
<ul>
<li><a href="chapters/Software_Testing/index.html#equivalent-class-testing-ect">Equivalent Class Testing (ECT)</a></li>
<li><a href="chapters/Software_Testing/index.html#weak--strong-ect">Weak / Strong ECT</a></li>
<li><a href="chapters/Software_Testing/index.html#boundary-value-testing-bvt">Boundary Value Testing (BVT)</a></li>
<li><a href="chapters/Software_Testing/index.html#limitations-bvt">Limitations BVT</a></li>
<li><a href="chapters/Software_Testing/index.html#robustness-testing">Robustness Testing</a></li>
<li><a href="chapters/Software_Testing/index.html#worst-case-testing-wct">Worst Case Testing (WCT)</a></li>
<li><a href="chapters/Software_Testing/index.html#category-partition-testing-cpt">Category Partition Testing (CPT)</a></li>
<li><a href="chapters/Software_Testing/index.html#decision-table-testing">Decision Table Testing</a></li>
<li><a href="chapters/Software_Testing/index.html#combinatorial-testing">Combinatorial Testing</a></li>
<li><a href="chapters/Software_Testing/index.html#profile-based-testing">Profile-Based Testing</a></li>
</ul>
</li>
<li><a href="chapters/Software_Testing/index.html#white-box-testing">White Box Testing</a></li>
</ul>
<hr />
<h2 id="foundations-of-testing"><a class="header" href="#foundations-of-testing">Foundations of Testing</a></h2>
<p><img src="chapters/Software_Testing/./images/image3.png" alt="Testing" /></p>
<p>Software testing are the techniques to execute programs with the intent of finding as many defects as possible and/or gaining sufficient confidence in the software system under test.</p>
<h3 id="test-case--test-suite"><a class="header" href="#test-case--test-suite">Test Case &amp; Test Suite</a></h3>
<ul>
<li><strong>Test Case</strong>: Is a set of inputs and the expected outputs for a system under test.</li>
<li><strong>Test Suite</strong>: Is a set of test cases.</li>
</ul>
<p>Without the expected outputs, a test case is not complete.</p>
<ul>
<li><strong>Direct Input Variable</strong>: A variable that controls the operation directly. Example: arguments, entered data, selection menu, etc.</li>
<li><strong>Indirect Input Variable</strong>: A variable that only influences the operations or its effects are propagated to the operation. Example: traffic load, environment variables, etc.</li>
</ul>
<h3 id="types-of-test-activities"><a class="header" href="#types-of-test-activities">Types of Test Activities</a></h3>
<ul>
<li><strong>Test-Case Design - Exploratory (human-based)</strong>: Design test values based on domain knowledge of the program and human knowledge of testing, exploratory testing.</li>
<li><strong>Test-Case Design - Criteria-based</strong>: Design test values to satisfy coverage or other engineering goal.</li>
<li><strong>Test-Case Automation</strong>: Embed test values into executable scripts.</li>
<li><strong>Test-Case Execution</strong>: Run tests on the software and record the results.</li>
<li><strong>Test-Case Evaluation</strong>: Evaluate the results of the testing, report to developers.</li>
</ul>
<hr />
<h2 id="software-testing-life-cycle-stlc"><a class="header" href="#software-testing-life-cycle-stlc">Software Testing Life Cycle (STLC)</a></h2>
<p><img src="chapters/Software_Testing/./images/image1.png" alt="Software Testing Life Cycle" /></p>
<ul>
<li>Requirement Analysis</li>
<li>Test Planning</li>
<li>Test Case Development</li>
<li>Environment Setup</li>
<li>Test Execution</li>
<li>Test Cycle Closure</li>
</ul>
<h4 id="requirements-analysis"><a class="header" href="#requirements-analysis">Requirements Analysis</a></h4>
<p>The process of analyzing the requirements from testing point of view to identify the testable requirements.</p>
<p>Requirements could be either:</p>
<ul>
<li><strong>Functional</strong>: Defining system software must do.</li>
<li><strong>Non-Functional</strong>: Defining system performance, security, availability, etc.</li>
</ul>
<h4 id="test-planning"><a class="header" href="#test-planning">Test Planning</a></h4>
<p>The process of defining the test strategy, test objectives, test estimation, test deliverables, test schedule, and test environment setup.</p>
<h4 id="test-case-development"><a class="header" href="#test-case-development">Test Case Development</a></h4>
<p>The process of developing test cases based on the test basis.</p>
<h4 id="environment-setup"><a class="header" href="#environment-setup">Environment Setup</a></h4>
<p>The process of setting up the test environment to execute the test cases.</p>
<h4 id="test-execution"><a class="header" href="#test-execution">Test Execution</a></h4>
<p>The process of executing the test cases and recording the results.</p>
<h4 id="test-cycle-closure"><a class="header" href="#test-cycle-closure">Test Cycle Closure</a></h4>
<p>The process of analyzing the test results, test logs, test reports, and test metrics obtained from the test execution phase to identify the test closure criteria.</p>
<hr />
<h2 id="unit-testing"><a class="header" href="#unit-testing">Unit Testing</a></h2>
<p>Ensure that each unit (i.e. subsystem, class or method) in isolation has been implemented correctly. Each method looks for a particular result and passes/fails. Often based on <code>white-box</code> testing.</p>
<h3 id="characteristics"><a class="header" href="#characteristics">Characteristics</a></h3>
<ul>
<li>A unit test must only test one specific unit of functionality (i.e class or method).</li>
<li>It is fast to execute.</li>
<li>It does not access a database or a file system.</li>
<li>It does not communicate via a network.</li>
<li>It does not require any special set up to the system environment such as modifying a configuration file.</li>
<li>It leaves the system and the system environment in the same state that it had prior to the test.</li>
<li>Focus on developed components only.</li>
</ul>
<h3 id="what-to-test"><a class="header" href="#what-to-test">What to test?</a></h3>
<ul>
<li>Focus on developed components and surroundings</li>
<li>One sample form each equivalent class of input data</li>
<li>Invalid data</li>
<li>Boundaries</li>
</ul>
<h3 id="when-to-test"><a class="header" href="#when-to-test">When to test?</a></h3>
<ul>
<li><strong>Waterfall</strong>: Typically written as the system has been developed.</li>
<li><strong>TDD</strong>: Each unit test is written before or during the corresponding code being written.</li>
</ul>
<h3 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h3>
<ul>
<li>Each test should test one thing only.</li>
<li>Each test method should have few assert statements.</li>
</ul>
<h2 id="junit"><a class="header" href="#junit">JUnit</a></h2>
<p><img src="chapters/Software_Testing/./images/image4.png" alt="JUnit" /></p>
<ul>
<li>Java testing framework used to write and run tests</li>
<li>Open source</li>
<li>Helps test execution automation</li>
</ul>
<h3 id="terminology-2"><a class="header" href="#terminology-2">Terminology</a></h3>
<ul>
<li><strong>Test Drivers</strong>: Modules that act as temporary replacement for a calling module and give the same output as that of the actual product.</li>
<li><strong>Test Execution</strong>: The execution of an individual unit test procedure.</li>
</ul>
<pre><code class="language-java">@BeforeEach // Optional (setup)

@Test // Required (test case)

@AfterEach // Optional (cleanup)
</code></pre>
<ul>
<li><strong>Test Result Formatter</strong>: A test runner produces results in once or more output formats, e.i. text, XML, HTML, etc.</li>
<li><strong>Assertions</strong>: An assertion is a function or macro that verifies the behavior (or state) of the unit under test.</li>
</ul>
<pre><code class="language-java">import static org.junit.Assert.*; // Import all static assert methods

public class TestClass {
  @Test
  public void testMethod() {
    assertEquals(1, 1);           // Compare two values
    assertNotEquals(1, 2);        // Compare two values
    assertTrue(true);             // Check if true
    assertFalse(false);           // Check if false
    assertNull(null);             // Check if null
    assertNotNull(1);             // Check if not null
    assertSame(1, 2);             // Check if object is same
    assertNotSame(1, 1.5);        // Check if object not same
    fail("Not yet implemented");  // Fail test
  }
}
</code></pre>
<h3 id="junit-test-class"><a class="header" href="#junit-test-class">JUnit Test Class</a></h3>
<ul>
<li>A method with <code>@Test</code> is flagged as JUnit test case.</li>
<li>All <code>@Test</code> methods run when JUnit runs your test class.</li>
</ul>
<pre><code class="language-java">import org.junit.Test;

public class TestClass {
  @Test
  public void testMethod() {
    // Test method
  }
}
</code></pre>
<h3 id="junit-test-suite"><a class="header" href="#junit-test-suite">JUnit Test Suite</a></h3>
<ul>
<li>A test suite is a collection of test cases.</li>
<li>The suite construction is done by using <code>@RunWith</code> and <code>@Suite</code> annotations.</li>
</ul>
<pre><code class="language-java">package com.example.tests; // Optional for running tests in command line

import org.junit.runner.RunWith;
import org.junit.runners.Suite;

@RunWith(Suite.class)
@Suite.SuiteClasses({
  TestClass1.class,
  TestClass2.class
})

public class TestSuite {}
</code></pre>
<h3 id="junit-test-runner"><a class="header" href="#junit-test-runner">JUnit Test Runner</a></h3>
<ul>
<li>Create a java class file named <code>TestRunner.java</code>.</li>
<li>Compile all the java classes using <code>javac</code> compiler.</li>
<li>Run the <code>TestRunner</code> class using <code>java</code> command.</li>
</ul>
<pre><code class="language-java">import org.junit.runner.JUnitCore;
import org.junit.runner.Result;
import org.junit.runner.notification.Failure;

public class TestRunner {
  public static void main(String[] args) {
    Result result = JUnitCore.runClasses(TestSuite.class);

    for (Failure failure : result.getFailures()) {
      System.out.println(failure.toString());
    }

    System.out.println(result.wasSuccessful());
  }
}
</code></pre>
<h3 id="junit-5"><a class="header" href="#junit-5">JUnit 5</a></h3>
<pre><code class="language-java">import static org.junit.Assert.*;

import org.junit.Before;
import org.junit.After;
import org.junit.Test;

public class TestClass {
  Tournament tournament;

  @BeforeEach // Optional (setup)
  public void before() throws Exception {
    System.out.println("Before");
    tournament = new Tournament(100, 60);
  }

  @Test // Required (test case)
  public void testGetBestTeam() {
    assertNotNull(tournament);

    Team team = tournament.getBestTeam();
    assertNotNull(team);
    assertEquals(100, team.getPoints());
  }

  @AfterEach // Optional (cleanup)
  public void after() throws Exception {
    System.out.println("After");
    tournament = null;
  }
}
</code></pre>
<h3 id="annotations"><a class="header" href="#annotations">Annotations</a></h3>
<p>Additional annotations for JUnit 5.</p>
<p><img src="chapters/Software_Testing/./images/image2.png" alt="JUnit Annotations" /></p>
<h3 id="ignoring-a-test"><a class="header" href="#ignoring-a-test">Ignoring a Test</a></h3>
<p>Use <code>@Ignore</code> annotation to ignore a test.</p>
<pre><code class="language-java">import org.junit.Disabled;

@Disabled("Disabled until bug #99 has been fixed")
@Test
public void testMethod() {
  // Test method to be ignored
}
</code></pre>
<h3 id="timeouts"><a class="header" href="#timeouts">Timeouts</a></h3>
<p>Use <code>timeout</code> parameter added to <code>@Test</code> annotation, with timeout parameter you can specify a value (in milliseconds) that you expect to be the upper limit of the time you spend executing your test.</p>
<pre><code class="language-java">import org.junit.Test;

@Test(timeout = 1000) // 1000 milliseconds
public void testTimeout() {
  // Test method
}
</code></pre>
<h3 id="expected-exceptions"><a class="header" href="#expected-exceptions">Expected Exceptions</a></h3>
<p>To catch (expected) exceptions thrown by JUnit tests, use <code>@Test</code> annotation's <code>expected</code> parameter.</p>
<pre><code class="language-java">import org.junit.Test;

@Test(expected = NotFoundException.class)
public void testNotFoundException() throws NotFoundException {
  // Test method
}
</code></pre>
<h3 id="data-driven-testing"><a class="header" href="#data-driven-testing">Data Driven Testing</a></h3>
<p>Data driven unit tests call a constructor for each collection of test values.</p>
<pre><code class="language-java">import org.junit.Test;
import org.junit.runner.RunWith;
import org.junit.runners.Parameterized;
import org.junit.runners.Parameterized.Parameters;
import static org.junit.Assert.assertTrue;

@RunWith(Parameterized.class) // Parameterized test runner
public class TestClass {
  private int a;
  private int b;
  private int sum;

  // Constructor
  public TestClass(int a, int b, int sum) {
    this.a = a;
    this.b = b;
    this.sum = sum;
  }

  @Parameters // Creating the set of test values
  public static Collection&lt;Object[]&gt; parameters() {
    return Arrays.asList(new Object[][] {
      { 1, 1, 2 },  // Test 1
      { 2, 2, 4 },  // Test 2
      { 3, 2, 5 },  // Test 3
      { 4, 3, 7 },  // Test 4
      { 5, 3, 8 }   // Test 5
    });
  }

  @BeforeAll // Setup
  public static void setUpCalculator() throws Exception {
    calculator = new Calculator();
  }

  @Test // Test case
  public void testAdd() {
    assertTrue("Addition Test", this.sum == calculator.add(this.a, this.b));
  }

  @AfterAll // Cleanup
  public static void tearDownCalculator() throws Exception {
    calculator = null;
  }
}
</code></pre>
<hr />
<h2 id="dependencies-using-doubles"><a class="header" href="#dependencies-using-doubles">Dependencies Using Doubles</a></h2>
<p><img src="chapters/Software_Testing/./images/image5.png" alt="Mockito" /></p>
<ul>
<li>Typically SUT (system under test) has dependencies.</li>
<li>Unit tests should not have dependencies.</li>
<li>If the SUT collaborates with any others classes, those classes are referred to as <code>depended on components</code> (DOC).</li>
<li>A test double is a replacement for a DOC.</li>
</ul>
<p>Example:</p>
<ol>
<li>A system might send an email to a user.</li>
<li>Since we do not want to send an email to a user every time we run a test, we use a test double to replace the email sending component.</li>
<li>We want to verify that the system sends an email to the user.</li>
</ol>
<p><strong>NOTE</strong>: External dependencies <em>MUST</em> be removed from unit testing.</p>
<h3 id="stubs"><a class="header" href="#stubs">Stubs</a></h3>
<ul>
<li>Is a fake class that comes with preprogrammed return values</li>
<li>It's injected into the class under test to give control over what's being tested as input.</li>
<li>Supplies responses to requests from the SUT.</li>
</ul>
<p>Example:</p>
<ul>
<li>A database connection that allows you to mimic any connection scenario without having s real database.</li>
</ul>
<h3 id="test-lifecycle-with-stubs"><a class="header" href="#test-lifecycle-with-stubs">Test Lifecycle with Stubs</a></h3>
<ol>
<li><strong>Setup</strong>: Prepare SUT that is being tested and its stubs collaborators. Usually in <code>@BeforeAll</code> method.</li>
<li><strong>Exercise</strong>: Test the functionality. Usually in <code>@Test</code> method.</li>
<li><strong>Verify State</strong>: Use asserts to check object's state.</li>
<li><strong>Teardown</strong>: Clean up resources. Unsually in <code>@AfterAll</code> method.</li>
</ol>
<h3 id="mocks"><a class="header" href="#mocks">Mocks</a></h3>
<ul>
<li>A fake object that decides whether a test has passed or failed by watching interactions between objects.</li>
<li>Dummy implementation of an interface or class in Mock framework.</li>
<li>Needed when a unit of code under test depends upon an external object.</li>
</ul>
<p>Example:</p>
<ul>
<li>You can ask it whether a method was called or how many times it was called. Typically mocks are classes with side effects that need to be examined.</li>
</ul>
<h3 id="test-lifecycle-with-mocks"><a class="header" href="#test-lifecycle-with-mocks">Test Lifecycle with Mocks</a></h3>
<ol>
<li><strong>Setup Data</strong>: Prepare object that is being tested.</li>
<li><strong>Setup Expectations</strong>: Prepare expectations in mock that is being used by primary object.</li>
<li><strong>Exercise</strong>: Test the functionality.</li>
<li><strong>Verify Expectations</strong>: Verify that correct methods have been invoked in mocks.</li>
<li><strong>Teardown</strong>: Clean up resources.</li>
</ol>
<h3 id="mockito"><a class="header" href="#mockito">Mockito</a></h3>
<ul>
<li>Is a mocking framework for Java.</li>
<li>Auto-generation of mock objects that implement a given interface.</li>
<li>Logging of what calls are made to the mock objects.</li>
</ul>
<pre><code class="language-java">// GradesService.java

public class GradesService {
  private final Gradebook gradebook;

  public GradesService(Gradebook gradebook) {
    this.gradebook = gradebook;
  }

  Double averageGrades(Student student) {
    return average(gradebook.gradesFor(student));
  }
}

</code></pre>
<pre><code class="language-java">// GradesServiceTest.java

import static org.mockito.Mockito.*;
import static org.junit.Assert.*;
import org.junit.*;

public class GradesServiceTest {
  private Gradebook gradebook;
  private Student student;

  @BeforeAll // Setup
  public static void setUp() {
    this.gradebook = mock(Gradebook.class);
    this.student = new Student();
  }

  @Test // Test case
  public void testAverageGrades() {
    when(gradebook.gradesFor(student)).thenReturn(grades(9.0, 8.0, 7.0));

    GradesService gradesService = new GradesService(this.gradebook);
    Double average = gradesService.averageGrades(this.student);

    assertEquals(8.0, average);
  }

  @AfterAll // Cleanup
  public static void cleanUp() {
    this.gradebook = null;
    this.student = null;
  }
}
</code></pre>
<ul>
<li><code>mock()</code> method takes a class or an interface as an argument and creates a mock object of given class or interface.</li>
<li><code>when()</code> method takes a method call on mock object as an argument and defines return value for that method call.</li>
<li><code>thenReturn()</code> method defines return value for the method call. If you specify more than one value, they will be returned in sequence until the last one is used.</li>
</ul>
<hr />
<h2 id="black-box-testing"><a class="header" href="#black-box-testing">Black Box Testing</a></h2>
<p><img src="chapters/Software_Testing/./images/image6.png" alt="Black Box Testing" /></p>
<p>Black Box testing applies at all granularity levels of testing.</p>
<ul>
<li>
<p><strong>Unit Testing</strong>: From module interface specification.</p>
</li>
<li>
<p><strong>Integration Testing</strong>: From the API or subsystem specification.</p>
</li>
<li>
<p><strong>System Testing</strong>: From the system specification.</p>
</li>
<li>
<p><strong>Regression Testing</strong>: From system requirements + bug history.</p>
</li>
</ul>
<h3 id="equivalent-class-testing-ect"><a class="header" href="#equivalent-class-testing-ect">Equivalent Class Testing (ECT)</a></h3>
<ul>
<li>
<p>You divide the set into partition that can be considered the same.</p>
</li>
<li>
<p>Partitions of input space in such a way that input data have the same effect on the system.</p>
</li>
<li>
<p>They all test the same unit (method, class, etc).</p>
</li>
<li>
<p>Entire input set is covered by the test cases.</p>
</li>
<li>
<p>They entire set of inputs can be divided into <code>Expected (E)</code> and <code>Unexpected (U)</code> inputs.</p>
</li>
</ul>
<h3 id="weak--strong-ect"><a class="header" href="#weak--strong-ect">Weak / Strong ECT</a></h3>
<ul>
<li><strong>Weak Equivalence Class Testing (one-dimensional)</strong>: Choosing one variable value form each equivalence class (one A, B, and C) such that all classes are covered.</li>
</ul>
<p><code>max(|A|, |B|, |C|)</code></p>
<p>Example:</p>
<ul>
<li>A = {1, 2, 3, 4}</li>
<li>B = {5, 6}</li>
<li>C = {7, 8, 9}</li>
</ul>
<p>max(4, 2, 3) = 4</p>
<ul>
<li><strong>Strong Equivalence Class Testing (multi-dimensional)</strong>: Based on the Cartesian product of the partition subsets (A x B x C). Testing all interactions of all equivalence classes.</li>
</ul>
<p><code>|A| x |B| x |C|</code></p>
<p>Example:</p>
<ul>
<li>A = {1, 2, 3, 4}</li>
<li>B = {5, 6}</li>
<li>C = {7, 8, 9}</li>
</ul>
<p>4 x 2 x 3 = 24</p>
<h3 id="boundary-value-testing-bvt"><a class="header" href="#boundary-value-testing-bvt">Boundary Value Testing (BVT)</a></h3>
<ul>
<li>
<p>While equivalence partitioning selects tests from within equivalence classes, boundary value analysis focuses on tests at and near the boundaries of equivalence classes.</p>
</li>
<li>
<p>Tests derived using either of the two techniques may overlap.</p>
</li>
<li>
<p>For each equivalence class, setting values for input variable just below the min, at the min, just above the min, a nominal value, just below the max, at the max and just above the max.</p>
</li>
<li>
<p>Typical strategy for all input variables: Holding the values of all but one variable at their nominal values, letting one variable take each of the above combinations.</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image8.png" alt="Boundary Value Testing" /></p>
<h3 id="limitations-bvt"><a class="header" href="#limitations-bvt">Limitations BVT</a></h3>
<p>For n independent variables, the number of test cases is:</p>
<p><code>4n + 1</code></p>
<p>Example:</p>
<p>Suppose we are testing a software module of an editor system that allows a user to enter new font identifiers into a font database. The following are the requirements for the font identifier:</p>
<ul>
<li>
<p>Spec. 1:</p>
<ul>
<li>
<p>C1. Font name is alphanumeric, valid</p>
</li>
<li>
<p>C2. Font name is not alphanumeric, invalid</p>
</li>
</ul>
</li>
<li>
<p>Spec. 2:</p>
<ul>
<li>
<p>C3. Font identifier has between 3 and 15 characters, valid</p>
</li>
<li>
<p>C4. Font identifier has less than 3 characters, invalid</p>
</li>
<li>
<p>C5. Font identifier has greater than 15 characters, invalid</p>
</li>
</ul>
</li>
<li>
<p>Spec. 3:</p>
<ul>
<li>
<p>C6. The first 2 characters are letters, valid</p>
</li>
<li>
<p>C7. The first 2 characters are not letters, invalid</p>
</li>
</ul>
</li>
</ul>
<p>For font identifier the values for the bounds groups are:</p>
<ul>
<li>
<p>BLB — 2</p>
</li>
<li>
<p>LB — 3</p>
</li>
<li>
<p>ALB — 4</p>
</li>
<li>
<p>BUB — 14</p>
</li>
<li>
<p>UB — 15</p>
</li>
<li>
<p>AUB — 16</p>
</li>
<li>
<p>NOM — anything between 4 and 14</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image7.png" alt="Boundary Value Testing" /></p>
<h3 id="robustness-testing"><a class="header" href="#robustness-testing">Robustness Testing</a></h3>
<ul>
<li>
<p>Robustness testing is the degree to which a component or system can function correctly in the presence of invalid inputs or stressful environmental conditions.</p>
</li>
<li>
<p>In Robustness testing the BLB and AUB are also included in test cases</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image9.png" alt="Robustness Testing" /></p>
<h3 id="worst-case-testing-wct"><a class="header" href="#worst-case-testing-wct">Worst Case Testing (WCT)</a></h3>
<ul>
<li>
<p>The worst case testing originates from the concept that more than one variable has extreme values.</p>
</li>
<li>
<p>Good strategy when physical variables have numerous interactions and failure is costly.</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image10.png" alt="Worst Case Testing" /></p>
<h3 id="category-partition-testing-cpt"><a class="header" href="#category-partition-testing-cpt">Category Partition Testing (CPT)</a></h3>
<ul>
<li>
<p>Combines boundary value analysis and equivalent classes with domain expertise.</p>
</li>
<li>
<p>You can define constraints as well.</p>
</li>
</ul>
<h3 id="decision-table-testing"><a class="header" href="#decision-table-testing">Decision Table Testing</a></h3>
<ul>
<li>
<p>Can help us deal with combination of inputs which produce different results, only one of which is correct.</p>
</li>
<li>
<p>Number of possible combinations is given by <code>2^n</code> (if binary), where n is the number of inputs.</p>
</li>
<li>
<p>Some combinations are meaningless and/or you cannot test all but you will choose a rich sub-set of the possible combinations using decision based testing technique.</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image11.png" alt="Decision Table Testing" /></p>
<h3 id="combinatorial-testing"><a class="header" href="#combinatorial-testing">Combinatorial Testing</a></h3>
<p>Combinatorial or t-way testing is a proven method for more effective testing at lower cost. NIST research showed that most software bugs and failures are caused by one or two parameters, with progressively fewer by three or more, which means that combinatorial testing can provide more efficient fault detection than conventional methods.</p>
<p><img src="chapters/Software_Testing/./images/image12.png" alt="Combinatorial Testing" /></p>
<ul>
<li>
<p><code>k</code> factors (number of parameters/configurations)</p>
</li>
<li>
<p><code>t</code> interactions (t-way testing)</p>
</li>
<li>
<p><code>l</code> levels: possible values for each factor</p>
</li>
</ul>
<p>The usage of NIST's combinatorial testing tool, Automated Combinatorial Testing for Software (ACTS), can help you to generate test cases for combinatorial testing.</p>
<p><a href="https://csrc.nist.gov/projects/automated-combinatorial-testing-for-software/downloadable-tools"><strong><em>Download ACTS</em></strong></a></p>
<h3 id="profile-based-testing"><a class="header" href="#profile-based-testing">Profile-Based Testing</a></h3>
<ul>
<li>
<p>Profile for a phenomenon is a set of disjoint alternatives called <strong><em>elements</em></strong> or <strong><em>features</em></strong> that represent that phenomenon together with their occurrence probabilities.</p>
</li>
<li>
<p>Operational Profile is the set of operations (operation names and frequencies) and their probabilities of occurrences.</p>
</li>
<li>
<p>Tabular representation is composed of a list of operation names and their probability of
occurrence.</p>
</li>
</ul>
<p>Example:</p>
<p>Assume that the following is the operational profile for a VCR system. The following table shows the usages scenario of each function depending on the starting state (rows) data that has been collected through analysis of customers’ behavior.</p>
<ul>
<li>
<p>Stop (STOP)</p>
</li>
<li>
<p>Rewind (REWIND)</p>
</li>
<li>
<p>Play (PLAY)</p>
</li>
<li>
<p>Fast Forward (FF)</p>
</li>
<li>
<p>Record (REC)</p>
</li>
</ul>
<p><img src="chapters/Software_Testing/./images/image13.png" alt="Profile-Based Testing" /></p>
<hr />
<h2 id="white-box-testing"><a class="header" href="#white-box-testing">White Box Testing</a></h2>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
